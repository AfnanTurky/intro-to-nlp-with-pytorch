{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Models\n",
    "This tutorial follows the [Sequence Models and Long-Short Term Memory Networks](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html) tutorial on the Pytorch webpage. The original author is Robert Guthrie.\n",
    "\n",
    "In this tutorial, you will learn about LSTM neural networks and see an example of how they can be used to recognize parts of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10d1e4a10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import jdc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import Image\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dave/DataScience/Projects/GitHub/PythonWorkshop/intro-to-nlp-with-pytorch/images\n"
     ]
    }
   ],
   "source": [
    "repo_dirpath = '/'.join(os.getcwd().split('/')[0:-1])\n",
    "image_dirpath = os.path.join(repo_dirpath, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/dave/DataScience/Projects/GitHub/PythonWorkshop/intro-to-nlp-with-pytorch/images/lstm_flow.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-afaec83158b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dirpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lstm_flow.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0;32m-> 1151\u001b[0;31m                 metadata=metadata)\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/dave/DataScience/Projects/GitHub/PythonWorkshop/intro-to-nlp-with-pytorch/images/lstm_flow.png'"
     ]
    }
   ],
   "source": [
    "Image(filename=os.path.join(image_dirpath, 'lstm_flow.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "### What is an LSTM?\n",
    "LSTM stands for Long Short-Term Memory. The network can learn sequences of information and make predictions based off of what it learns. It is a type of recurrent neural network. The LSTM cell has a state, which gets updated as the network trains. It is this state that allows the network to remember.\n",
    "\n",
    "Here is a basic diagram of an LSTM:\n",
    "<img src=os.path.join(image_dirpath, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Components\n",
    "An LSTM cell consists of three gates. Each gate makes decisions on what information to pass on. The gates are:\n",
    "* Forget Gate\n",
    "* Input Gate\n",
    "* Output Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forget Gate\n",
    "This gate decides what information is not important and removes it from the current LSTM state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Gate.\n",
    "The input gate decides what information to store in the current LSTM state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Gate\n",
    "Finally, the LSTM decides what information to output. This is done through the output gate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Simple Example 1\n",
    "Before approaching the main example for this tutorial, let's see a very brief example of how to create and LSTM cell in Pytorch and pass information through it. One way to do this is using a **`for`** loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dimension is 3, output dimension is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # Make a sequence of length 5\n",
    "\n",
    "# Initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # After each time step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: tensor([[[-0.3600,  0.0893,  0.0215]]])\n",
      "hidden: (tensor([[[-0.3600,  0.0893,  0.0215]]]), tensor([[[-1.1298,  0.4467,  0.0254]]]))\n"
     ]
    }
   ],
   "source": [
    "print('out: {}'.format(out))\n",
    "print('hidden: {}'.format(hidden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Simple Example 2\n",
    "Instead of creating an LSTM using a **`for`** loop, we can use Pytorch's **`cat`** function to string together each layer of the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dimension is 3, output dimension is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # Make a sequence of length 5\n",
    "\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # Clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: tensor([[[-0.2696,  0.2599, -0.0758]],\n",
      "\n",
      "        [[-0.4923,  0.1408, -0.0738]],\n",
      "\n",
      "        [[-0.4523,  0.1241, -0.1461]],\n",
      "\n",
      "        [[-0.3057,  0.1198, -0.0571]],\n",
      "\n",
      "        [[-0.1077,  0.0289, -0.0487]]])\n",
      "hidden: (tensor([[[-0.1077,  0.0289, -0.0487]]]), tensor([[[-0.1439,  0.1426, -0.2563]]]))\n"
     ]
    }
   ],
   "source": [
    "print('out: {}'.format(out))\n",
    "print('hidden: {}'.format(hidden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: An LSTM for Part-of-Speech Tagging\n",
    "In this example, a model will be created that can predict the part-of-speech for each word in a sentence. TODO: Show rolled out LSTM, labeling each word and part of speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data:\n",
    "Let's begin by creating a dataset for training. The dataset will consist of a list of sequences. Each sequence will contain two lists. The first list is a sentence split up into words. The second list contains grammmer identifiers for each word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    (\"The dog ate the apple.\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book.\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "training_sentences = [training_data[x][0] for x in range(len(training_data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Pytorch only understands numbers, we need to map strings, such as the words in the training set, to integers. The following lines of code create a dictionary with this mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_to_ix: {'that': 7, 'The': 0, 'Everybody': 5, 'read': 6, 'apple.': 4, 'the': 3, 'ate': 2, 'book.': 8, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {}\n",
    "for sentence, tags in training_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print('word_to_ix: {}'.format(word_to_ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to map the parts-of-speech tags to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags to integers\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A third dictionary is used to map the integers back to parts-of-speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integers to tags\n",
    "ix_to_tag = {0: \"DET\", 1: \"NN\", 2: \"V\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "LEARNING_RATE = 0.1\n",
    "NUM_EPOCHS = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "We will define the model by creating a Python class object. This class will inherit the nn.Module class from Pytorch, which will allow us to easily use the neural network classes defined in Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LSTMTagger` class will take in four values, the embedding dimension, the number of hidden dimensions, the vocabulary size, and the size of the tag set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # LSTM: Inputs are embeddings, outputs are hidden states\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # Linear layer maps hidden space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a function to initialize the hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to LSTMTagger\n",
    "def init_hidden(self):\n",
    "    # Initialize the hidden state. The axes correspond to \n",
    "    # (num_layers, minibatch_size, hidden_dim)\n",
    "    return (torch.zeros(1, 1, self.hidden_dim),\n",
    "            torch.zeros(1, 1, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function to make a forward pass through the recurrent LSTM network. It will return the predict tag values given an input sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to LSTMTagger\n",
    "def forward(self, sentence):\n",
    "    embeds = self.word_embeddings(sentence)\n",
    "    lstm_out, self.hidden = self.lstm(\n",
    "        embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "    tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "    tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "    return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function\n",
    "This helper function will be used to map either words or tags to integers, using the previously defined dictionaries (**`tag_to_ix`**, **`ix_to_tag`**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    \"\"\"\n",
    "    Convert words or tags to intigers and return a Pytorch tensor.\n",
    "    :params seq: Sequence of words.\n",
    "    :type seq: list\n",
    "    :params to_ix: Dictionary mapping words or tags to intigers.\n",
    "    :return: A Pytorch tensor of indices.\n",
    "    :rtype: Tensor\n",
    "    \"\"\"\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the LSTM Pytorch model using the hyperparameters defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define in the loss function. In this case, we will be using a negative log likelihood function, which is useful in classification problems. TODO: Diagram of loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the model using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the model before any training has been done and store the scores to a `list`. We will then compare these scores with the scores after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_initial_scores = []\n",
    "store_initial_predictions = []\n",
    "with torch.no_grad():\n",
    "    for sentence in training_sentences:\n",
    "        inputs = prepare_sequence(sentence, word_to_ix)\n",
    "        tag_scores = model(inputs)\n",
    "        max_values, max_indices = torch.max(tag_scores, 1)\n",
    "        initial_prediction = [ix_to_tag[x] for x in max_indices.numpy()]\n",
    "        store_initial_predictions.append(initial_prediction)\n",
    "        store_initial_scores.append(tag_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    for sentence, tags in training_data:\n",
    "        # Set gradients equal to zero after each intance\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Initialize hidden state of LSTM after each intance\n",
    "        model.hidden = model.init_hidden()\n",
    "        \n",
    "        # Turn inputs into tensors of word indices\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "        \n",
    "        # Run forward pass\n",
    "        tag_scores = model(sentence_in)\n",
    "        \n",
    "        # Compute the loss, gradients, and update the parameters\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has now finished training. Let's print out some statistics to show how well the model training performed. TODO: Understand what numbers for scores mean and create diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      " - initial scores: tensor([[-1.1737, -1.1350, -0.9960],\n",
      "        [-1.1711, -1.2007, -0.9442],\n",
      "        [-1.2051, -1.1736, -0.9389],\n",
      "        [-1.1577, -1.1514, -0.9954],\n",
      "        [-1.1466, -1.1302, -1.0236]])\n",
      " - sentence: The dog ate the apple.\n",
      " - predicition: ['V', 'V', 'V', 'V', 'V']\n",
      "After training:\n",
      " - final scores: tensor([[-0.3653, -1.2979, -3.4145],\n",
      "        [-2.6583, -0.1817, -2.3428],\n",
      "        [-2.8464, -3.7458, -0.0852],\n",
      "        [-0.1884, -3.2050, -2.0312],\n",
      "        [-4.5199, -0.0146, -5.6265]])\n",
      " - sentence: The dog ate the apple.\n",
      " - prediction: ['DET', 'NN', 'V', 'DET', 'NN']\n",
      "\n",
      "Before training:\n",
      " - initial scores: tensor([[-1.1579, -1.1226, -1.0204],\n",
      "        [-1.1322, -1.0778, -1.0867],\n",
      "        [-1.0748, -1.0915, -1.1304],\n",
      "        [-1.1071, -1.0693, -1.1202]])\n",
      " - sentence: Everybody read that book.\n",
      " - predicition: ['V', 'NN', 'DET', 'NN']\n",
      "After training:\n",
      " - final scores: tensor([[-5.1919, -0.0250, -3.9576],\n",
      "        [-2.1640, -2.9561, -0.1826],\n",
      "        [-0.0306, -4.4853, -3.9704],\n",
      "        [-4.4139, -0.0137, -6.5122]])\n",
      " - sentence: Everybody read that book.\n",
      " - prediction: ['NN', 'V', 'DET', 'NN']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the scores after training the model\n",
    "store_initial_scores.reverse()\n",
    "store_initial_predictions.reverse()\n",
    "with torch.no_grad():\n",
    "    for sentence in training_sentences:\n",
    "        inputs = prepare_sequence(sentence, word_to_ix)\n",
    "        tag_scores = model(inputs)\n",
    "        max_values, max_indices = torch.max(tag_scores, 1)\n",
    "        predictions = [ix_to_tag[x] for x in max_indices.numpy()]\n",
    "        \n",
    "        print('Before training:')\n",
    "        print(' - initial scores: {}'.format(store_initial_scores.pop()))\n",
    "        print(' - sentence: {}'.format(' '.join(sentence)))\n",
    "        print(' - predicition: {}'.format(store_initial_predictions.pop()))\n",
    "        print('After training:')\n",
    "        print(' - final scores: {}'.format(tag_scores))\n",
    "        print(' - sentence: {}'.format(' '.join(sentence)))\n",
    "        print(' - prediction: {}'.format(predictions))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do the scores mean?\n",
    "The scores are used to predict the parts-of-speech for each word in a sentence. A corresponding list of of possible parts-of-speech is assigned to each word. This list is the same for all data passed through the model. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us take the sentence: The dog ate the apple.\n",
      "For the word \"The\" the list of possible parts-of-speech are: ['DET', 'NN', 'V']\n"
     ]
    }
   ],
   "source": [
    "print('Let us take the sentence: {}'.format(' '.join(training_sentences[0])))\n",
    "print('For the word \"{}\" the list of possible parts-of-speech are: {}'.format(training_sentences[0][0], [x for x in ix_to_tag.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model assigns a scores to each part-of-speech in the list. The prediction is then the part-of-speech with the highest score. If the model makes a correct prediction, then `DET` will have the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
