{"id": 33, "text": "You can also obtain the TensorFlow version with: 1. TF 1.0: python -c import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION) 2. TF 2.0: python -c import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)", "annotations": [{"label": 4, "start_offset": 4, "end_offset": 7, "user": 1}, {"label": 4, "start_offset": 8, "end_offset": 12, "user": 1}, {"label": 4, "start_offset": 13, "end_offset": 19, "user": 1}, {"label": 4, "start_offset": 20, "end_offset": 23, "user": 1}, {"label": 4, "start_offset": 24, "end_offset": 34, "user": 1}, {"label": 4, "start_offset": 35, "end_offset": 42, "user": 1}, {"label": 4, "start_offset": 43, "end_offset": 48, "user": 1}, {"label": 4, "start_offset": 49, "end_offset": 51, "user": 1}, {"label": 4, "start_offset": 52, "end_offset": 54, "user": 1}, {"label": 4, "start_offset": 55, "end_offset": 59, "user": 1}, {"label": 4, "start_offset": 60, "end_offset": 66, "user": 1}, {"label": 4, "start_offset": 67, "end_offset": 69, "user": 1}, {"label": 2, "start_offset": 70, "end_offset": 76, "user": 1}, {"label": 3, "start_offset": 77, "end_offset": 87, "user": 1}, {"label": 3, "start_offset": 88, "end_offset": 90, "user": 1}, {"label": 3, "start_offset": 91, "end_offset": 94, "user": 1}, {"label": 3, "start_offset": 95, "end_offset": 100, "user": 1}, {"label": 3, "start_offset": 100, "end_offset": 116, "user": 1}, {"label": 3, "start_offset": 117, "end_offset": 128, "user": 1}, {"label": 4, "start_offset": 129, "end_offset": 131, "user": 1}, {"label": 4, "start_offset": 132, "end_offset": 134, "user": 1}, {"label": 4, "start_offset": 135, "end_offset": 139, "user": 1}, {"label": 4, "start_offset": 140, "end_offset": 146, "user": 1}, {"label": 4, "start_offset": 147, "end_offset": 149, "user": 1}, {"label": 2, "start_offset": 150, "end_offset": 156, "user": 1}, {"label": 3, "start_offset": 157, "end_offset": 167, "user": 1}, {"label": 3, "start_offset": 168, "end_offset": 170, "user": 1}, {"label": 3, "start_offset": 171, "end_offset": 174, "user": 1}, {"label": 3, "start_offset": 175, "end_offset": 204, "user": 1}, {"label": 3, "start_offset": 205, "end_offset": 224, "user": 1}, {"label": 4, "start_offset": 0, "end_offset": 3, "user": 1}], "meta": {}}
{"id": 34, "text": "This makes it harder to understand the behavior of the function tf.scatter_add in case indices is a matrix. Specifically, what is the difference between tf.scatter_add and tf.scatter_nd when indices is a matrix.  This will raise an error that only sequential or functional models can be saved model.save('custom_model.h5')", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 4, "user": 1}, {"label": 4, "start_offset": 5, "end_offset": 10, "user": 1}, {"label": 4, "start_offset": 11, "end_offset": 13, "user": 1}, {"label": 4, "start_offset": 14, "end_offset": 20, "user": 1}, {"label": 4, "start_offset": 21, "end_offset": 23, "user": 1}, {"label": 4, "start_offset": 24, "end_offset": 34, "user": 1}, {"label": 4, "start_offset": 35, "end_offset": 38, "user": 1}, {"label": 4, "start_offset": 39, "end_offset": 47, "user": 1}, {"label": 4, "start_offset": 48, "end_offset": 50, "user": 1}, {"label": 4, "start_offset": 51, "end_offset": 54, "user": 1}, {"label": 4, "start_offset": 55, "end_offset": 63, "user": 1}, {"label": 2, "start_offset": 64, "end_offset": 78, "user": 1}, {"label": 4, "start_offset": 79, "end_offset": 81, "user": 1}, {"label": 4, "start_offset": 82, "end_offset": 86, "user": 1}, {"label": 4, "start_offset": 87, "end_offset": 94, "user": 1}, {"label": 4, "start_offset": 95, "end_offset": 97, "user": 1}, {"label": 4, "start_offset": 98, "end_offset": 99, "user": 1}, {"label": 4, "start_offset": 100, "end_offset": 106, "user": 1}, {"label": 4, "start_offset": 108, "end_offset": 120, "user": 1}, {"label": 4, "start_offset": 122, "end_offset": 126, "user": 1}, {"label": 4, "start_offset": 127, "end_offset": 129, "user": 1}, {"label": 4, "start_offset": 130, "end_offset": 133, "user": 1}, {"label": 4, "start_offset": 134, "end_offset": 144, "user": 1}, {"label": 4, "start_offset": 145, "end_offset": 152, "user": 1}, {"label": 2, "start_offset": 153, "end_offset": 167, "user": 1}, {"label": 4, "start_offset": 168, "end_offset": 171, "user": 1}, {"label": 2, "start_offset": 172, "end_offset": 186, "user": 1}, {"label": 4, "start_offset": 186, "end_offset": 190, "user": 1}, {"label": 4, "start_offset": 191, "end_offset": 198, "user": 1}, {"label": 4, "start_offset": 199, "end_offset": 201, "user": 1}, {"label": 4, "start_offset": 202, "end_offset": 203, "user": 1}, {"label": 4, "start_offset": 204, "end_offset": 210, "user": 1}, {"label": 4, "start_offset": 213, "end_offset": 217, "user": 1}, {"label": 4, "start_offset": 218, "end_offset": 222, "user": 1}, {"label": 4, "start_offset": 223, "end_offset": 228, "user": 1}, {"label": 4, "start_offset": 229, "end_offset": 231, "user": 1}, {"label": 4, "start_offset": 232, "end_offset": 237, "user": 1}, {"label": 4, "start_offset": 238, "end_offset": 242, "user": 1}, {"label": 4, "start_offset": 243, "end_offset": 247, "user": 1}, {"label": 4, "start_offset": 248, "end_offset": 258, "user": 1}, {"label": 4, "start_offset": 259, "end_offset": 261, "user": 1}, {"label": 4, "start_offset": 262, "end_offset": 272, "user": 1}, {"label": 4, "start_offset": 273, "end_offset": 279, "user": 1}, {"label": 4, "start_offset": 280, "end_offset": 283, "user": 1}, {"label": 4, "start_offset": 284, "end_offset": 286, "user": 1}, {"label": 4, "start_offset": 287, "end_offset": 292, "user": 1}, {"label": 2, "start_offset": 293, "end_offset": 322, "user": 1}], "meta": {}}
{"id": 35, "text": "Now, I'm ready to move this to a serving environment (via Sagemaker, but that just implements tensorflow.serving).", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 3, "user": 1}, {"label": 4, "start_offset": 5, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 14, "user": 1}, {"label": 4, "start_offset": 15, "end_offset": 17, "user": 1}, {"label": 4, "start_offset": 18, "end_offset": 22, "user": 1}, {"label": 4, "start_offset": 23, "end_offset": 27, "user": 1}, {"label": 4, "start_offset": 28, "end_offset": 30, "user": 1}, {"label": 4, "start_offset": 31, "end_offset": 32, "user": 1}, {"label": 4, "start_offset": 33, "end_offset": 40, "user": 1}, {"label": 4, "start_offset": 41, "end_offset": 52, "user": 1}, {"label": 4, "start_offset": 54, "end_offset": 57, "user": 1}, {"label": 4, "start_offset": 58, "end_offset": 67, "user": 1}, {"label": 4, "start_offset": 69, "end_offset": 72, "user": 1}, {"label": 4, "start_offset": 73, "end_offset": 77, "user": 1}, {"label": 4, "start_offset": 78, "end_offset": 82, "user": 1}, {"label": 4, "start_offset": 83, "end_offset": 93, "user": 1}, {"label": 2, "start_offset": 94, "end_offset": 112, "user": 1}], "meta": {}}
{"id": 36, "text": "The issue seems to come from a call to Trackable._gather_saveables_for_checkpoint which is not overridden by tf.Module or AutoTrackable.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 3, "user": 1}, {"label": 4, "start_offset": 4, "end_offset": 9, "user": 1}, {"label": 4, "start_offset": 10, "end_offset": 15, "user": 1}, {"label": 4, "start_offset": 16, "end_offset": 18, "user": 1}, {"label": 4, "start_offset": 19, "end_offset": 23, "user": 1}, {"label": 4, "start_offset": 24, "end_offset": 28, "user": 1}, {"label": 4, "start_offset": 29, "end_offset": 30, "user": 1}, {"label": 4, "start_offset": 31, "end_offset": 35, "user": 1}, {"label": 4, "start_offset": 36, "end_offset": 38, "user": 1}, {"label": 2, "start_offset": 39, "end_offset": 81, "user": 1}, {"label": 4, "start_offset": 82, "end_offset": 87, "user": 1}, {"label": 4, "start_offset": 88, "end_offset": 90, "user": 1}, {"label": 4, "start_offset": 91, "end_offset": 94, "user": 1}, {"label": 4, "start_offset": 95, "end_offset": 105, "user": 1}, {"label": 4, "start_offset": 106, "end_offset": 108, "user": 1}, {"label": 2, "start_offset": 109, "end_offset": 118, "user": 1}, {"label": 2, "start_offset": 122, "end_offset": 135, "user": 1}, {"label": 4, "start_offset": 119, "end_offset": 121, "user": 1}], "meta": {}}
{"id": 37, "text": "The docs for tf.train.Saver call for a list/dict of SaveableObject, which AutoTrackable is not, but it seems odd that it isn't. It is possible that I am misunderstanding the SaveableObject/Saver API, but I do feel like AutoTrackable should be compatible tf.train.Saver.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 3, "user": 1}, {"label": 4, "start_offset": 4, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 12, "user": 1}, {"label": 2, "start_offset": 13, "end_offset": 27, "user": 1}, {"label": 4, "start_offset": 28, "end_offset": 32, "user": 1}, {"label": 4, "start_offset": 33, "end_offset": 36, "user": 1}, {"label": 4, "start_offset": 37, "end_offset": 38, "user": 1}, {"label": 4, "start_offset": 39, "end_offset": 48, "user": 1}, {"label": 4, "start_offset": 49, "end_offset": 51, "user": 1}, {"label": 2, "start_offset": 52, "end_offset": 66, "user": 1}, {"label": 4, "start_offset": 68, "end_offset": 73, "user": 1}, {"label": 2, "start_offset": 74, "end_offset": 87, "user": 1}, {"label": 4, "start_offset": 88, "end_offset": 90, "user": 1}, {"label": 4, "start_offset": 91, "end_offset": 94, "user": 1}, {"label": 4, "start_offset": 96, "end_offset": 99, "user": 1}, {"label": 4, "start_offset": 100, "end_offset": 102, "user": 1}, {"label": 4, "start_offset": 103, "end_offset": 108, "user": 1}, {"label": 4, "start_offset": 109, "end_offset": 112, "user": 1}, {"label": 4, "start_offset": 113, "end_offset": 117, "user": 1}, {"label": 4, "start_offset": 118, "end_offset": 120, "user": 1}, {"label": 4, "start_offset": 121, "end_offset": 126, "user": 1}, {"label": 4, "start_offset": 128, "end_offset": 130, "user": 1}, {"label": 4, "start_offset": 131, "end_offset": 133, "user": 1}, {"label": 4, "start_offset": 134, "end_offset": 142, "user": 1}, {"label": 4, "start_offset": 143, "end_offset": 147, "user": 1}, {"label": 4, "start_offset": 148, "end_offset": 149, "user": 1}, {"label": 4, "start_offset": 150, "end_offset": 152, "user": 1}, {"label": 4, "start_offset": 153, "end_offset": 169, "user": 1}, {"label": 4, "start_offset": 170, "end_offset": 173, "user": 1}, {"label": 4, "start_offset": 174, "end_offset": 194, "user": 1}, {"label": 4, "start_offset": 195, "end_offset": 198, "user": 1}, {"label": 4, "start_offset": 200, "end_offset": 203, "user": 1}, {"label": 4, "start_offset": 204, "end_offset": 205, "user": 1}, {"label": 4, "start_offset": 206, "end_offset": 208, "user": 1}, {"label": 4, "start_offset": 209, "end_offset": 213, "user": 1}, {"label": 4, "start_offset": 214, "end_offset": 218, "user": 1}, {"label": 2, "start_offset": 219, "end_offset": 232, "user": 1}, {"label": 4, "start_offset": 233, "end_offset": 239, "user": 1}, {"label": 4, "start_offset": 240, "end_offset": 242, "user": 1}, {"label": 4, "start_offset": 243, "end_offset": 253, "user": 1}, {"label": 2, "start_offset": 254, "end_offset": 268, "user": 1}], "meta": {}}
{"id": 38, "text": "Please use tf.train.Checkpoint rather than tf.train.Saver to save objects: https://www.tensorflow.org/beta/guide/checkpoints (the guide is for 2.x, but the APIs are in 1.x as well).", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 6, "user": 1}, {"label": 4, "start_offset": 7, "end_offset": 10, "user": 1}, {"label": 2, "start_offset": 11, "end_offset": 30, "user": 1}, {"label": 4, "start_offset": 31, "end_offset": 37, "user": 1}, {"label": 4, "start_offset": 38, "end_offset": 42, "user": 1}, {"label": 2, "start_offset": 43, "end_offset": 57, "user": 1}, {"label": 4, "start_offset": 58, "end_offset": 60, "user": 1}, {"label": 4, "start_offset": 61, "end_offset": 65, "user": 1}, {"label": 4, "start_offset": 66, "end_offset": 73, "user": 1}, {"label": 4, "start_offset": 75, "end_offset": 124, "user": 1}, {"label": 4, "start_offset": 126, "end_offset": 129, "user": 1}, {"label": 4, "start_offset": 130, "end_offset": 135, "user": 1}, {"label": 4, "start_offset": 136, "end_offset": 138, "user": 1}, {"label": 4, "start_offset": 139, "end_offset": 142, "user": 1}, {"label": 4, "start_offset": 143, "end_offset": 146, "user": 1}, {"label": 4, "start_offset": 148, "end_offset": 151, "user": 1}, {"label": 4, "start_offset": 152, "end_offset": 155, "user": 1}, {"label": 4, "start_offset": 156, "end_offset": 160, "user": 1}, {"label": 4, "start_offset": 161, "end_offset": 164, "user": 1}, {"label": 4, "start_offset": 165, "end_offset": 167, "user": 1}, {"label": 4, "start_offset": 168, "end_offset": 171, "user": 1}, {"label": 4, "start_offset": 172, "end_offset": 174, "user": 1}, {"label": 4, "start_offset": 175, "end_offset": 179, "user": 1}], "meta": {}}
{"id": 39, "text": "There is a mismatch in the name of libtensorflow_framework and the tf.sysconfig.get_link_flag name. As an example TF-Addons uses this to link with tensorflow core.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 5, "user": 1}, {"label": 4, "start_offset": 6, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 10, "user": 1}, {"label": 4, "start_offset": 11, "end_offset": 19, "user": 1}, {"label": 4, "start_offset": 20, "end_offset": 22, "user": 1}, {"label": 4, "start_offset": 23, "end_offset": 26, "user": 1}, {"label": 4, "start_offset": 27, "end_offset": 31, "user": 1}, {"label": 4, "start_offset": 32, "end_offset": 34, "user": 1}, {"label": 2, "start_offset": 35, "end_offset": 58, "user": 1}, {"label": 4, "start_offset": 59, "end_offset": 62, "user": 1}, {"label": 4, "start_offset": 63, "end_offset": 66, "user": 1}, {"label": 2, "start_offset": 67, "end_offset": 93, "user": 1}, {"label": 4, "start_offset": 94, "end_offset": 98, "user": 1}, {"label": 4, "start_offset": 100, "end_offset": 102, "user": 1}, {"label": 4, "start_offset": 103, "end_offset": 105, "user": 1}, {"label": 4, "start_offset": 106, "end_offset": 113, "user": 1}, {"label": 4, "start_offset": 114, "end_offset": 123, "user": 1}, {"label": 4, "start_offset": 124, "end_offset": 128, "user": 1}, {"label": 4, "start_offset": 129, "end_offset": 133, "user": 1}, {"label": 4, "start_offset": 134, "end_offset": 136, "user": 1}, {"label": 4, "start_offset": 137, "end_offset": 141, "user": 1}, {"label": 4, "start_offset": 142, "end_offset": 146, "user": 1}, {"label": 4, "start_offset": 147, "end_offset": 157, "user": 1}, {"label": 4, "start_offset": 158, "end_offset": 162, "user": 1}], "meta": {}}
{"id": 40, "text": "I am encountering serialization issues when trying to dump the config from a tf.keras.Model object without complex things like custom layers (or even Lambdas...).  The code worked well with tf 1.13.1 however in tf 1.1.4, json/yaml serialization fails, and to_yaml and model_from_yaml fails as well.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 1, "user": 1}, {"label": 4, "start_offset": 2, "end_offset": 4, "user": 1}, {"label": 4, "start_offset": 5, "end_offset": 17, "user": 1}, {"label": 4, "start_offset": 18, "end_offset": 31, "user": 1}, {"label": 4, "start_offset": 32, "end_offset": 38, "user": 1}, {"label": 4, "start_offset": 39, "end_offset": 43, "user": 1}, {"label": 4, "start_offset": 44, "end_offset": 50, "user": 1}, {"label": 4, "start_offset": 51, "end_offset": 53, "user": 1}, {"label": 4, "start_offset": 54, "end_offset": 58, "user": 1}, {"label": 4, "start_offset": 59, "end_offset": 62, "user": 1}, {"label": 2, "start_offset": 63, "end_offset": 69, "user": 1}, {"label": 4, "start_offset": 70, "end_offset": 74, "user": 1}, {"label": 4, "start_offset": 75, "end_offset": 76, "user": 1}, {"label": 2, "start_offset": 77, "end_offset": 91, "user": 1}, {"label": 4, "start_offset": 92, "end_offset": 98, "user": 1}, {"label": 4, "start_offset": 99, "end_offset": 106, "user": 1}, {"label": 4, "start_offset": 107, "end_offset": 114, "user": 1}, {"label": 4, "start_offset": 115, "end_offset": 121, "user": 1}, {"label": 4, "start_offset": 122, "end_offset": 126, "user": 1}, {"label": 4, "start_offset": 127, "end_offset": 133, "user": 1}, {"label": 4, "start_offset": 134, "end_offset": 140, "user": 1}, {"label": 4, "start_offset": 142, "end_offset": 144, "user": 1}, {"label": 4, "start_offset": 145, "end_offset": 149, "user": 1}, {"label": 4, "start_offset": 150, "end_offset": 160, "user": 1}, {"label": 4, "start_offset": 164, "end_offset": 167, "user": 1}, {"label": 4, "start_offset": 168, "end_offset": 172, "user": 1}, {"label": 4, "start_offset": 173, "end_offset": 179, "user": 1}, {"label": 4, "start_offset": 180, "end_offset": 184, "user": 1}, {"label": 4, "start_offset": 185, "end_offset": 189, "user": 1}, {"label": 4, "start_offset": 190, "end_offset": 192, "user": 1}, {"label": 4, "start_offset": 193, "end_offset": 199, "user": 1}, {"label": 4, "start_offset": 200, "end_offset": 207, "user": 1}, {"label": 4, "start_offset": 208, "end_offset": 210, "user": 1}, {"label": 4, "start_offset": 211, "end_offset": 213, "user": 1}, {"label": 4, "start_offset": 214, "end_offset": 219, "user": 1}, {"label": 4, "start_offset": 221, "end_offset": 230, "user": 1}, {"label": 4, "start_offset": 231, "end_offset": 244, "user": 1}, {"label": 4, "start_offset": 245, "end_offset": 250, "user": 1}, {"label": 4, "start_offset": 252, "end_offset": 255, "user": 1}, {"label": 2, "start_offset": 256, "end_offset": 263, "user": 1}, {"label": 4, "start_offset": 264, "end_offset": 267, "user": 1}, {"label": 2, "start_offset": 268, "end_offset": 283, "user": 1}, {"label": 4, "start_offset": 284, "end_offset": 289, "user": 1}, {"label": 4, "start_offset": 290, "end_offset": 292, "user": 1}, {"label": 4, "start_offset": 293, "end_offset": 297, "user": 1}], "meta": {}}
{"id": 41, "text": "I'm not sure if I understand it correctly, but this seems similar to computing the argmax over a single dimension, via argmax(2). Or am I missing something?", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 3, "user": 1}, {"label": 4, "start_offset": 4, "end_offset": 7, "user": 1}, {"label": 4, "start_offset": 8, "end_offset": 12, "user": 1}, {"label": 4, "start_offset": 13, "end_offset": 15, "user": 1}, {"label": 4, "start_offset": 16, "end_offset": 17, "user": 1}, {"label": 4, "start_offset": 18, "end_offset": 28, "user": 1}, {"label": 4, "start_offset": 29, "end_offset": 31, "user": 1}, {"label": 4, "start_offset": 32, "end_offset": 41, "user": 1}, {"label": 4, "start_offset": 43, "end_offset": 46, "user": 1}, {"label": 4, "start_offset": 47, "end_offset": 51, "user": 1}, {"label": 4, "start_offset": 52, "end_offset": 57, "user": 1}, {"label": 4, "start_offset": 58, "end_offset": 65, "user": 1}, {"label": 4, "start_offset": 66, "end_offset": 68, "user": 1}, {"label": 4, "start_offset": 69, "end_offset": 78, "user": 1}, {"label": 4, "start_offset": 79, "end_offset": 82, "user": 1}, {"label": 4, "start_offset": 83, "end_offset": 89, "user": 1}, {"label": 4, "start_offset": 90, "end_offset": 94, "user": 1}, {"label": 4, "start_offset": 95, "end_offset": 96, "user": 1}, {"label": 4, "start_offset": 97, "end_offset": 103, "user": 1}, {"label": 4, "start_offset": 104, "end_offset": 113, "user": 1}, {"label": 4, "start_offset": 115, "end_offset": 118, "user": 1}, {"label": 2, "start_offset": 119, "end_offset": 128, "user": 1}, {"label": 4, "start_offset": 130, "end_offset": 132, "user": 1}, {"label": 4, "start_offset": 133, "end_offset": 135, "user": 1}, {"label": 4, "start_offset": 136, "end_offset": 137, "user": 1}, {"label": 4, "start_offset": 138, "end_offset": 145, "user": 1}, {"label": 4, "start_offset": 146, "end_offset": 155, "user": 1}], "meta": {}}
{"id": 42, "text": "I don't know the underlying reason why you need to call torch.functional.stft, we did not export the torch.functional library to torchscript yet. You will need to call torch.stft in JIT and pass all the necessary arguments for it.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 1, "user": 1}, {"label": 4, "start_offset": 2, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 8, "end_offset": 12, "user": 1}, {"label": 4, "start_offset": 13, "end_offset": 16, "user": 1}, {"label": 4, "start_offset": 17, "end_offset": 27, "user": 1}, {"label": 4, "start_offset": 28, "end_offset": 34, "user": 1}, {"label": 4, "start_offset": 35, "end_offset": 38, "user": 1}, {"label": 4, "start_offset": 39, "end_offset": 42, "user": 1}, {"label": 4, "start_offset": 43, "end_offset": 47, "user": 1}, {"label": 4, "start_offset": 48, "end_offset": 50, "user": 1}, {"label": 4, "start_offset": 51, "end_offset": 55, "user": 1}, {"label": 2, "start_offset": 56, "end_offset": 77, "user": 1}, {"label": 4, "start_offset": 79, "end_offset": 81, "user": 1}, {"label": 4, "start_offset": 82, "end_offset": 85, "user": 1}, {"label": 4, "start_offset": 86, "end_offset": 89, "user": 1}, {"label": 4, "start_offset": 90, "end_offset": 96, "user": 1}, {"label": 4, "start_offset": 97, "end_offset": 100, "user": 1}, {"label": 2, "start_offset": 101, "end_offset": 118, "user": 1}, {"label": 4, "start_offset": 118, "end_offset": 125, "user": 1}, {"label": 4, "start_offset": 126, "end_offset": 128, "user": 1}, {"label": 4, "start_offset": 129, "end_offset": 140, "user": 1}, {"label": 4, "start_offset": 141, "end_offset": 144, "user": 1}, {"label": 4, "start_offset": 146, "end_offset": 149, "user": 1}, {"label": 4, "start_offset": 150, "end_offset": 154, "user": 1}, {"label": 4, "start_offset": 155, "end_offset": 159, "user": 1}, {"label": 4, "start_offset": 160, "end_offset": 162, "user": 1}, {"label": 4, "start_offset": 163, "end_offset": 167, "user": 1}, {"label": 2, "start_offset": 167, "end_offset": 178, "user": 1}, {"label": 4, "start_offset": 179, "end_offset": 181, "user": 1}, {"label": 4, "start_offset": 182, "end_offset": 185, "user": 1}, {"label": 4, "start_offset": 186, "end_offset": 189, "user": 1}, {"label": 4, "start_offset": 190, "end_offset": 194, "user": 1}, {"label": 4, "start_offset": 195, "end_offset": 198, "user": 1}, {"label": 4, "start_offset": 199, "end_offset": 202, "user": 1}, {"label": 4, "start_offset": 203, "end_offset": 212, "user": 1}, {"label": 4, "start_offset": 213, "end_offset": 222, "user": 1}, {"label": 4, "start_offset": 223, "end_offset": 226, "user": 1}, {"label": 4, "start_offset": 227, "end_offset": 229, "user": 1}], "meta": {}}
{"id": 43, "text": "Don't we need to pass retain_graph=True to backward if we want to compute the derivative again?", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 5, "user": 1}, {"label": 4, "start_offset": 6, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 13, "user": 1}, {"label": 4, "start_offset": 14, "end_offset": 16, "user": 1}, {"label": 4, "start_offset": 17, "end_offset": 21, "user": 1}, {"label": 2, "start_offset": 22, "end_offset": 39, "user": 1}, {"label": 4, "start_offset": 40, "end_offset": 42, "user": 1}, {"label": 2, "start_offset": 43, "end_offset": 51, "user": 1}, {"label": 4, "start_offset": 52, "end_offset": 54, "user": 1}, {"label": 4, "start_offset": 55, "end_offset": 57, "user": 1}, {"label": 4, "start_offset": 58, "end_offset": 62, "user": 1}, {"label": 4, "start_offset": 63, "end_offset": 65, "user": 1}, {"label": 4, "start_offset": 66, "end_offset": 73, "user": 1}, {"label": 4, "start_offset": 74, "end_offset": 77, "user": 1}, {"label": 4, "start_offset": 78, "end_offset": 88, "user": 1}, {"label": 4, "start_offset": 89, "end_offset": 94, "user": 1}], "meta": {}}
{"id": 44, "text": "When using Conv1d with a large kernel size (1024 for instance) on gpu, the cudnn implementation is very slow and gets slower as I increase the kernel size. I thought it was using FFT but apparently not. If it were using FFT, the computation time should be independent of the kernel size, because the kernel is anyway padded to the length of the input.  I have tried benchmarking with both torch.backends.cudnn.benchmark set to False and True. My implementation using the FFT is significantly faster especially when using a stride of 1. You will find hereafter the code both for the FFT based convolution implementation I use and the profiling. My implementation is within ~5e-5 of the reference implementation for random weights and input. For a kernel size of 1024, with 64 channels, a stride of 1 and an input of length 64000, the default implementation is about 20 times slower than the FFT based one. When using a kernel size of 2048, it is 40 times slower.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 4, "user": 1}, {"label": 4, "start_offset": 5, "end_offset": 10, "user": 1}, {"label": 4, "start_offset": 18, "end_offset": 22, "user": 1}, {"label": 4, "start_offset": 23, "end_offset": 24, "user": 1}, {"label": 4, "start_offset": 25, "end_offset": 30, "user": 1}, {"label": 4, "start_offset": 31, "end_offset": 37, "user": 1}, {"label": 4, "start_offset": 38, "end_offset": 42, "user": 1}, {"label": 4, "start_offset": 44, "end_offset": 48, "user": 1}, {"label": 4, "start_offset": 49, "end_offset": 52, "user": 1}, {"label": 4, "start_offset": 53, "end_offset": 61, "user": 1}, {"label": 4, "start_offset": 63, "end_offset": 65, "user": 1}, {"label": 4, "start_offset": 66, "end_offset": 69, "user": 1}, {"label": 4, "start_offset": 71, "end_offset": 74, "user": 1}, {"label": 4, "start_offset": 75, "end_offset": 80, "user": 1}, {"label": 4, "start_offset": 81, "end_offset": 95, "user": 1}, {"label": 4, "start_offset": 96, "end_offset": 98, "user": 1}, {"label": 4, "start_offset": 99, "end_offset": 103, "user": 1}, {"label": 4, "start_offset": 104, "end_offset": 108, "user": 1}, {"label": 4, "start_offset": 109, "end_offset": 112, "user": 1}, {"label": 4, "start_offset": 113, "end_offset": 117, "user": 1}, {"label": 4, "start_offset": 118, "end_offset": 124, "user": 1}, {"label": 4, "start_offset": 125, "end_offset": 127, "user": 1}, {"label": 4, "start_offset": 128, "end_offset": 129, "user": 1}, {"label": 4, "start_offset": 130, "end_offset": 138, "user": 1}, {"label": 4, "start_offset": 139, "end_offset": 142, "user": 1}, {"label": 4, "start_offset": 143, "end_offset": 149, "user": 1}, {"label": 4, "start_offset": 150, "end_offset": 154, "user": 1}, {"label": 4, "start_offset": 156, "end_offset": 157, "user": 1}, {"label": 4, "start_offset": 158, "end_offset": 165, "user": 1}, {"label": 4, "start_offset": 166, "end_offset": 168, "user": 1}, {"label": 4, "start_offset": 169, "end_offset": 172, "user": 1}, {"label": 4, "start_offset": 173, "end_offset": 178, "user": 1}, {"label": 4, "start_offset": 179, "end_offset": 182, "user": 1}, {"label": 4, "start_offset": 183, "end_offset": 186, "user": 1}, {"label": 4, "start_offset": 187, "end_offset": 197, "user": 1}, {"label": 4, "start_offset": 198, "end_offset": 201, "user": 1}, {"label": 4, "start_offset": 203, "end_offset": 205, "user": 1}, {"label": 4, "start_offset": 206, "end_offset": 208, "user": 1}, {"label": 2, "start_offset": 389, "end_offset": 419, "user": 1}, {"label": 2, "start_offset": 427, "end_offset": 432, "user": 1}, {"label": 2, "start_offset": 437, "end_offset": 441, "user": 1}, {"label": 4, "start_offset": 209, "end_offset": 213, "user": 1}, {"label": 4, "start_offset": 214, "end_offset": 219, "user": 1}, {"label": 4, "start_offset": 220, "end_offset": 223, "user": 1}, {"label": 4, "start_offset": 225, "end_offset": 228, "user": 1}, {"label": 4, "start_offset": 229, "end_offset": 240, "user": 1}, {"label": 4, "start_offset": 241, "end_offset": 245, "user": 1}, {"label": 4, "start_offset": 246, "end_offset": 252, "user": 1}, {"label": 4, "start_offset": 253, "end_offset": 255, "user": 1}, {"label": 4, "start_offset": 256, "end_offset": 267, "user": 1}, {"label": 4, "start_offset": 268, "end_offset": 270, "user": 1}, {"label": 2, "start_offset": 11, "end_offset": 17, "user": 1}, {"label": 4, "start_offset": 271, "end_offset": 274, "user": 1}, {"label": 4, "start_offset": 275, "end_offset": 281, "user": 1}, {"label": 4, "start_offset": 282, "end_offset": 286, "user": 1}, {"label": 4, "start_offset": 288, "end_offset": 295, "user": 1}, {"label": 4, "start_offset": 296, "end_offset": 299, "user": 1}, {"label": 4, "start_offset": 300, "end_offset": 306, "user": 1}, {"label": 4, "start_offset": 307, "end_offset": 309, "user": 1}, {"label": 4, "start_offset": 310, "end_offset": 316, "user": 1}, {"label": 4, "start_offset": 317, "end_offset": 323, "user": 1}, {"label": 4, "start_offset": 324, "end_offset": 326, "user": 1}, {"label": 4, "start_offset": 327, "end_offset": 330, "user": 1}, {"label": 4, "start_offset": 331, "end_offset": 337, "user": 1}, {"label": 4, "start_offset": 338, "end_offset": 340, "user": 1}, {"label": 4, "start_offset": 341, "end_offset": 344, "user": 1}, {"label": 4, "start_offset": 345, "end_offset": 350, "user": 1}, {"label": 4, "start_offset": 353, "end_offset": 354, "user": 1}, {"label": 4, "start_offset": 355, "end_offset": 359, "user": 1}, {"label": 4, "start_offset": 360, "end_offset": 365, "user": 1}, {"label": 4, "start_offset": 366, "end_offset": 378, "user": 1}, {"label": 4, "start_offset": 379, "end_offset": 383, "user": 1}, {"label": 4, "start_offset": 384, "end_offset": 388, "user": 1}, {"label": 4, "start_offset": 420, "end_offset": 423, "user": 1}, {"label": 4, "start_offset": 424, "end_offset": 426, "user": 1}, {"label": 4, "start_offset": 433, "end_offset": 436, "user": 1}, {"label": 4, "start_offset": 443, "end_offset": 445, "user": 1}, {"label": 4, "start_offset": 446, "end_offset": 460, "user": 1}, {"label": 4, "start_offset": 461, "end_offset": 466, "user": 1}, {"label": 4, "start_offset": 467, "end_offset": 470, "user": 1}, {"label": 4, "start_offset": 471, "end_offset": 474, "user": 1}, {"label": 4, "start_offset": 475, "end_offset": 477, "user": 1}, {"label": 4, "start_offset": 478, "end_offset": 491, "user": 1}, {"label": 4, "start_offset": 492, "end_offset": 498, "user": 1}, {"label": 4, "start_offset": 499, "end_offset": 509, "user": 1}, {"label": 4, "start_offset": 510, "end_offset": 514, "user": 1}, {"label": 4, "start_offset": 515, "end_offset": 520, "user": 1}, {"label": 4, "start_offset": 521, "end_offset": 522, "user": 1}, {"label": 4, "start_offset": 523, "end_offset": 529, "user": 1}, {"label": 4, "start_offset": 530, "end_offset": 532, "user": 1}, {"label": 4, "start_offset": 533, "end_offset": 534, "user": 1}, {"label": 4, "start_offset": 536, "end_offset": 539, "user": 1}, {"label": 4, "start_offset": 540, "end_offset": 544, "user": 1}, {"label": 4, "start_offset": 545, "end_offset": 549, "user": 1}, {"label": 4, "start_offset": 550, "end_offset": 559, "user": 1}, {"label": 4, "start_offset": 560, "end_offset": 563, "user": 1}, {"label": 4, "start_offset": 564, "end_offset": 568, "user": 1}, {"label": 4, "start_offset": 569, "end_offset": 573, "user": 1}, {"label": 4, "start_offset": 574, "end_offset": 577, "user": 1}, {"label": 4, "start_offset": 578, "end_offset": 581, "user": 1}, {"label": 4, "start_offset": 582, "end_offset": 585, "user": 1}, {"label": 4, "start_offset": 586, "end_offset": 591, "user": 1}, {"label": 4, "start_offset": 592, "end_offset": 603, "user": 1}, {"label": 4, "start_offset": 604, "end_offset": 618, "user": 1}, {"label": 4, "start_offset": 619, "end_offset": 620, "user": 1}, {"label": 4, "start_offset": 621, "end_offset": 624, "user": 1}, {"label": 4, "start_offset": 625, "end_offset": 628, "user": 1}, {"label": 4, "start_offset": 629, "end_offset": 632, "user": 1}, {"label": 4, "start_offset": 633, "end_offset": 642, "user": 1}, {"label": 4, "start_offset": 644, "end_offset": 646, "user": 1}, {"label": 4, "start_offset": 647, "end_offset": 661, "user": 1}, {"label": 4, "start_offset": 662, "end_offset": 664, "user": 1}, {"label": 4, "start_offset": 665, "end_offset": 671, "user": 1}, {"label": 4, "start_offset": 672, "end_offset": 677, "user": 1}, {"label": 4, "start_offset": 678, "end_offset": 680, "user": 1}, {"label": 4, "start_offset": 681, "end_offset": 684, "user": 1}, {"label": 4, "start_offset": 685, "end_offset": 694, "user": 1}, {"label": 4, "start_offset": 695, "end_offset": 709, "user": 1}, {"label": 4, "start_offset": 710, "end_offset": 713, "user": 1}, {"label": 4, "start_offset": 714, "end_offset": 720, "user": 1}, {"label": 4, "start_offset": 721, "end_offset": 728, "user": 1}, {"label": 4, "start_offset": 729, "end_offset": 732, "user": 1}, {"label": 4, "start_offset": 733, "end_offset": 738, "user": 1}, {"label": 4, "start_offset": 740, "end_offset": 743, "user": 1}, {"label": 4, "start_offset": 744, "end_offset": 745, "user": 1}, {"label": 4, "start_offset": 746, "end_offset": 752, "user": 1}, {"label": 4, "start_offset": 753, "end_offset": 757, "user": 1}, {"label": 4, "start_offset": 758, "end_offset": 760, "user": 1}, {"label": 4, "start_offset": 761, "end_offset": 765, "user": 1}, {"label": 4, "start_offset": 767, "end_offset": 771, "user": 1}, {"label": 4, "start_offset": 772, "end_offset": 774, "user": 1}, {"label": 4, "start_offset": 775, "end_offset": 783, "user": 1}, {"label": 4, "start_offset": 785, "end_offset": 786, "user": 1}, {"label": 4, "start_offset": 787, "end_offset": 793, "user": 1}, {"label": 4, "start_offset": 794, "end_offset": 796, "user": 1}, {"label": 4, "start_offset": 797, "end_offset": 798, "user": 1}, {"label": 4, "start_offset": 799, "end_offset": 802, "user": 1}, {"label": 4, "start_offset": 803, "end_offset": 805, "user": 1}, {"label": 4, "start_offset": 806, "end_offset": 811, "user": 1}, {"label": 4, "start_offset": 812, "end_offset": 814, "user": 1}, {"label": 4, "start_offset": 815, "end_offset": 821, "user": 1}, {"label": 4, "start_offset": 822, "end_offset": 827, "user": 1}, {"label": 4, "start_offset": 829, "end_offset": 832, "user": 1}, {"label": 4, "start_offset": 833, "end_offset": 840, "user": 1}, {"label": 4, "start_offset": 841, "end_offset": 855, "user": 1}, {"label": 4, "start_offset": 856, "end_offset": 858, "user": 1}, {"label": 4, "start_offset": 859, "end_offset": 864, "user": 1}, {"label": 4, "start_offset": 865, "end_offset": 867, "user": 1}, {"label": 4, "start_offset": 868, "end_offset": 873, "user": 1}, {"label": 4, "start_offset": 874, "end_offset": 880, "user": 1}, {"label": 4, "start_offset": 881, "end_offset": 885, "user": 1}, {"label": 4, "start_offset": 886, "end_offset": 889, "user": 1}, {"label": 4, "start_offset": 890, "end_offset": 893, "user": 1}, {"label": 4, "start_offset": 894, "end_offset": 899, "user": 1}, {"label": 4, "start_offset": 900, "end_offset": 903, "user": 1}, {"label": 4, "start_offset": 905, "end_offset": 909, "user": 1}, {"label": 4, "start_offset": 910, "end_offset": 915, "user": 1}, {"label": 4, "start_offset": 916, "end_offset": 917, "user": 1}, {"label": 4, "start_offset": 918, "end_offset": 924, "user": 1}, {"label": 4, "start_offset": 925, "end_offset": 929, "user": 1}, {"label": 4, "start_offset": 930, "end_offset": 932, "user": 1}, {"label": 4, "start_offset": 933, "end_offset": 937, "user": 1}, {"label": 4, "start_offset": 939, "end_offset": 941, "user": 1}, {"label": 4, "start_offset": 942, "end_offset": 944, "user": 1}, {"label": 4, "start_offset": 945, "end_offset": 947, "user": 1}, {"label": 4, "start_offset": 948, "end_offset": 953, "user": 1}, {"label": 4, "start_offset": 954, "end_offset": 960, "user": 1}], "meta": {}}
{"id": 45, "text": "There is also another point that I'd like to make about grid_sample, which is that even after we make this change to make it aligned, it won't match 1:1 with interpolate in some cases.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 5, "user": 1}, {"label": 4, "start_offset": 6, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 13, "user": 1}, {"label": 4, "start_offset": 14, "end_offset": 21, "user": 1}, {"label": 4, "start_offset": 22, "end_offset": 27, "user": 1}, {"label": 4, "start_offset": 28, "end_offset": 32, "user": 1}, {"label": 4, "start_offset": 33, "end_offset": 36, "user": 1}, {"label": 4, "start_offset": 37, "end_offset": 41, "user": 1}, {"label": 4, "start_offset": 42, "end_offset": 44, "user": 1}, {"label": 4, "start_offset": 45, "end_offset": 49, "user": 1}, {"label": 4, "start_offset": 50, "end_offset": 55, "user": 1}, {"label": 2, "start_offset": 56, "end_offset": 67, "user": 1}, {"label": 4, "start_offset": 69, "end_offset": 74, "user": 1}, {"label": 4, "start_offset": 75, "end_offset": 77, "user": 1}, {"label": 4, "start_offset": 78, "end_offset": 82, "user": 1}, {"label": 4, "start_offset": 83, "end_offset": 87, "user": 1}, {"label": 4, "start_offset": 88, "end_offset": 93, "user": 1}, {"label": 4, "start_offset": 94, "end_offset": 96, "user": 1}, {"label": 4, "start_offset": 97, "end_offset": 101, "user": 1}, {"label": 4, "start_offset": 102, "end_offset": 106, "user": 1}, {"label": 4, "start_offset": 107, "end_offset": 113, "user": 1}, {"label": 4, "start_offset": 114, "end_offset": 116, "user": 1}, {"label": 4, "start_offset": 117, "end_offset": 121, "user": 1}, {"label": 4, "start_offset": 122, "end_offset": 124, "user": 1}, {"label": 4, "start_offset": 125, "end_offset": 132, "user": 1}, {"label": 4, "start_offset": 134, "end_offset": 136, "user": 1}, {"label": 4, "start_offset": 137, "end_offset": 142, "user": 1}, {"label": 4, "start_offset": 143, "end_offset": 148, "user": 1}, {"label": 4, "start_offset": 149, "end_offset": 152, "user": 1}, {"label": 4, "start_offset": 153, "end_offset": 157, "user": 1}, {"label": 2, "start_offset": 158, "end_offset": 169, "user": 1}, {"label": 4, "start_offset": 170, "end_offset": 172, "user": 1}, {"label": 4, "start_offset": 173, "end_offset": 177, "user": 1}, {"label": 4, "start_offset": 178, "end_offset": 183, "user": 1}], "meta": {}}
{"id": 46, "text": "If self.transform_input is true, then x_ch0 = torch.unsqueeze(...) will be converted to onnx operators:", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 2, "user": 1}, {"label": 2, "start_offset": 3, "end_offset": 24, "user": 1}, {"label": 4, "start_offset": 24, "end_offset": 26, "user": 1}, {"label": 4, "start_offset": 27, "end_offset": 31, "user": 1}, {"label": 4, "start_offset": 33, "end_offset": 37, "user": 1}, {"label": 2, "start_offset": 38, "end_offset": 43, "user": 1}, {"label": 3, "start_offset": 44, "end_offset": 45, "user": 1}, {"label": 3, "start_offset": 46, "end_offset": 66, "user": 1}, {"label": 4, "start_offset": 67, "end_offset": 71, "user": 1}, {"label": 4, "start_offset": 72, "end_offset": 74, "user": 1}, {"label": 4, "start_offset": 75, "end_offset": 84, "user": 1}, {"label": 4, "start_offset": 85, "end_offset": 87, "user": 1}, {"label": 2, "start_offset": 88, "end_offset": 92, "user": 1}, {"label": 4, "start_offset": 93, "end_offset": 102, "user": 1}], "meta": {}}
{"id": 49, "text": "After #19228 , setting batch_size=None (and batch_sampler=None) disables autobatching (auto collation) and advanced use cases can handle batching themselves.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 5, "user": 1}, {"label": 4, "start_offset": 6, "end_offset": 13, "user": 1}, {"label": 4, "start_offset": 15, "end_offset": 22, "user": 1}, {"label": 2, "start_offset": 23, "end_offset": 38, "user": 1}, {"label": 4, "start_offset": 40, "end_offset": 43, "user": 1}, {"label": 2, "start_offset": 44, "end_offset": 62, "user": 1}, {"label": 4, "start_offset": 64, "end_offset": 72, "user": 1}, {"label": 4, "start_offset": 73, "end_offset": 85, "user": 1}, {"label": 4, "start_offset": 87, "end_offset": 91, "user": 1}, {"label": 4, "start_offset": 92, "end_offset": 101, "user": 1}, {"label": 4, "start_offset": 103, "end_offset": 106, "user": 1}, {"label": 4, "start_offset": 107, "end_offset": 115, "user": 1}, {"label": 4, "start_offset": 116, "end_offset": 119, "user": 1}, {"label": 4, "start_offset": 120, "end_offset": 125, "user": 1}, {"label": 4, "start_offset": 126, "end_offset": 129, "user": 1}, {"label": 4, "start_offset": 130, "end_offset": 136, "user": 1}, {"label": 4, "start_offset": 137, "end_offset": 145, "user": 1}, {"label": 4, "start_offset": 146, "end_offset": 156, "user": 1}], "meta": {}}
{"id": 50, "text": "Seems like it should be False for backwards compatibility. We should probably add a record_shapes option to emit_nvtx's __init__", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 5, "user": 1}, {"label": 4, "start_offset": 6, "end_offset": 10, "user": 1}, {"label": 4, "start_offset": 11, "end_offset": 13, "user": 1}, {"label": 4, "start_offset": 14, "end_offset": 20, "user": 1}, {"label": 4, "start_offset": 21, "end_offset": 23, "user": 1}, {"label": 2, "start_offset": 24, "end_offset": 29, "user": 1}, {"label": 4, "start_offset": 30, "end_offset": 33, "user": 1}, {"label": 4, "start_offset": 34, "end_offset": 43, "user": 1}, {"label": 4, "start_offset": 44, "end_offset": 57, "user": 1}, {"label": 4, "start_offset": 59, "end_offset": 61, "user": 1}, {"label": 4, "start_offset": 62, "end_offset": 68, "user": 1}, {"label": 4, "start_offset": 69, "end_offset": 77, "user": 1}, {"label": 4, "start_offset": 78, "end_offset": 81, "user": 1}, {"label": 3, "start_offset": 82, "end_offset": 83, "user": 1}, {"label": 2, "start_offset": 84, "end_offset": 97, "user": 1}, {"label": 4, "start_offset": 98, "end_offset": 104, "user": 1}, {"label": 4, "start_offset": 105, "end_offset": 107, "user": 1}, {"label": 2, "start_offset": 108, "end_offset": 117, "user": 1}, {"label": 3, "start_offset": 120, "end_offset": 128, "user": 1}], "meta": {}}
{"id": 51, "text": "Do nvtx ranges support adding extra information (like the input shapes)? Not sure if record_shapes makes sense for emit_nvtx", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 2, "user": 1}, {"label": 2, "start_offset": 3, "end_offset": 7, "user": 1}, {"label": 4, "start_offset": 8, "end_offset": 14, "user": 1}, {"label": 4, "start_offset": 15, "end_offset": 22, "user": 1}, {"label": 4, "start_offset": 23, "end_offset": 29, "user": 1}, {"label": 4, "start_offset": 30, "end_offset": 35, "user": 1}, {"label": 4, "start_offset": 36, "end_offset": 47, "user": 1}, {"label": 4, "start_offset": 49, "end_offset": 53, "user": 1}, {"label": 4, "start_offset": 54, "end_offset": 57, "user": 1}, {"label": 4, "start_offset": 58, "end_offset": 63, "user": 1}, {"label": 4, "start_offset": 64, "end_offset": 70, "user": 1}, {"label": 4, "start_offset": 73, "end_offset": 76, "user": 1}, {"label": 4, "start_offset": 77, "end_offset": 81, "user": 1}, {"label": 4, "start_offset": 82, "end_offset": 84, "user": 1}, {"label": 2, "start_offset": 85, "end_offset": 98, "user": 1}, {"label": 4, "start_offset": 99, "end_offset": 104, "user": 1}, {"label": 4, "start_offset": 105, "end_offset": 110, "user": 1}, {"label": 4, "start_offset": 111, "end_offset": 114, "user": 1}, {"label": 2, "start_offset": 115, "end_offset": 124, "user": 1}], "meta": {}}
{"id": 52, "text": "Mutable dictionary string type stops working after assigning value in dictionary. The line print torch.ops.map_rasterizer_utils.ends_with(key, '_cont') works when called before assigning the key to the frame_dictionary but not after.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 7, "user": 1}, {"label": 4, "start_offset": 8, "end_offset": 18, "user": 1}, {"label": 4, "start_offset": 19, "end_offset": 25, "user": 1}, {"label": 4, "start_offset": 26, "end_offset": 30, "user": 1}, {"label": 4, "start_offset": 31, "end_offset": 36, "user": 1}, {"label": 4, "start_offset": 37, "end_offset": 44, "user": 1}, {"label": 4, "start_offset": 45, "end_offset": 50, "user": 1}, {"label": 4, "start_offset": 51, "end_offset": 60, "user": 1}, {"label": 4, "start_offset": 61, "end_offset": 66, "user": 1}, {"label": 4, "start_offset": 67, "end_offset": 69, "user": 1}, {"label": 4, "start_offset": 70, "end_offset": 80, "user": 1}, {"label": 4, "start_offset": 82, "end_offset": 85, "user": 1}, {"label": 4, "start_offset": 86, "end_offset": 90, "user": 1}, {"label": 2, "start_offset": 91, "end_offset": 96, "user": 1}, {"label": 3, "start_offset": 97, "end_offset": 151, "user": 1}, {"label": 4, "start_offset": 152, "end_offset": 157, "user": 1}, {"label": 4, "start_offset": 158, "end_offset": 162, "user": 1}, {"label": 4, "start_offset": 163, "end_offset": 169, "user": 1}, {"label": 4, "start_offset": 170, "end_offset": 176, "user": 1}, {"label": 4, "start_offset": 177, "end_offset": 186, "user": 1}, {"label": 4, "start_offset": 187, "end_offset": 190, "user": 1}, {"label": 4, "start_offset": 191, "end_offset": 194, "user": 1}, {"label": 4, "start_offset": 195, "end_offset": 197, "user": 1}, {"label": 4, "start_offset": 198, "end_offset": 201, "user": 1}, {"label": 2, "start_offset": 202, "end_offset": 218, "user": 1}, {"label": 4, "start_offset": 219, "end_offset": 222, "user": 1}, {"label": 4, "start_offset": 223, "end_offset": 226, "user": 1}, {"label": 4, "start_offset": 227, "end_offset": 232, "user": 1}], "meta": {}}
{"id": 53, "text": "As described here the output size of torch.arange is int((end-start)/step) (i.e. the floor). But it's the ceiling:", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 2, "user": 1}, {"label": 4, "start_offset": 3, "end_offset": 12, "user": 1}, {"label": 4, "start_offset": 13, "end_offset": 17, "user": 1}, {"label": 4, "start_offset": 18, "end_offset": 21, "user": 1}, {"label": 4, "start_offset": 22, "end_offset": 28, "user": 1}, {"label": 4, "start_offset": 29, "end_offset": 33, "user": 1}, {"label": 4, "start_offset": 34, "end_offset": 36, "user": 1}, {"label": 2, "start_offset": 37, "end_offset": 49, "user": 1}, {"label": 4, "start_offset": 50, "end_offset": 52, "user": 1}, {"label": 2, "start_offset": 53, "end_offset": 74, "user": 1}, {"label": 4, "start_offset": 76, "end_offset": 80, "user": 1}, {"label": 4, "start_offset": 81, "end_offset": 84, "user": 1}, {"label": 2, "start_offset": 85, "end_offset": 90, "user": 1}, {"label": 4, "start_offset": 93, "end_offset": 96, "user": 1}, {"label": 4, "start_offset": 97, "end_offset": 101, "user": 1}, {"label": 4, "start_offset": 102, "end_offset": 105, "user": 1}, {"label": 2, "start_offset": 106, "end_offset": 113, "user": 1}], "meta": {}}
{"id": 54, "text": "torch.bernoulli shows two extra parameters other than the two documented ones: * and generator=None", "annotations": [{"label": 2, "start_offset": 0, "end_offset": 15, "user": 1}, {"label": 4, "start_offset": 16, "end_offset": 21, "user": 1}, {"label": 4, "start_offset": 22, "end_offset": 25, "user": 1}, {"label": 4, "start_offset": 26, "end_offset": 31, "user": 1}, {"label": 4, "start_offset": 32, "end_offset": 42, "user": 1}, {"label": 4, "start_offset": 43, "end_offset": 48, "user": 1}, {"label": 4, "start_offset": 49, "end_offset": 53, "user": 1}, {"label": 4, "start_offset": 54, "end_offset": 57, "user": 1}, {"label": 4, "start_offset": 58, "end_offset": 61, "user": 1}, {"label": 4, "start_offset": 62, "end_offset": 72, "user": 1}, {"label": 4, "start_offset": 73, "end_offset": 77, "user": 1}, {"label": 4, "start_offset": 79, "end_offset": 80, "user": 1}, {"label": 4, "start_offset": 81, "end_offset": 84, "user": 1}, {"label": 2, "start_offset": 85, "end_offset": 99, "user": 1}], "meta": {}}
{"id": 55, "text": "Consider making it a parameter or input, or detaching the gradient when use torch.jit.ScriptModule without torch.jit.script_method forward. It can work normally when I replace torch.jit.ScriptModule to nn.Module.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 15, "user": 1}, {"label": 4, "start_offset": 16, "end_offset": 18, "user": 1}, {"label": 4, "start_offset": 19, "end_offset": 20, "user": 1}, {"label": 4, "start_offset": 21, "end_offset": 30, "user": 1}, {"label": 4, "start_offset": 31, "end_offset": 33, "user": 1}, {"label": 4, "start_offset": 34, "end_offset": 39, "user": 1}, {"label": 4, "start_offset": 41, "end_offset": 43, "user": 1}, {"label": 4, "start_offset": 44, "end_offset": 53, "user": 1}, {"label": 4, "start_offset": 54, "end_offset": 57, "user": 1}, {"label": 4, "start_offset": 58, "end_offset": 66, "user": 1}, {"label": 4, "start_offset": 67, "end_offset": 71, "user": 1}, {"label": 4, "start_offset": 72, "end_offset": 75, "user": 1}, {"label": 2, "start_offset": 76, "end_offset": 98, "user": 1}, {"label": 4, "start_offset": 99, "end_offset": 106, "user": 1}, {"label": 2, "start_offset": 107, "end_offset": 130, "user": 1}, {"label": 4, "start_offset": 140, "end_offset": 142, "user": 1}, {"label": 4, "start_offset": 143, "end_offset": 146, "user": 1}, {"label": 4, "start_offset": 147, "end_offset": 151, "user": 1}, {"label": 4, "start_offset": 152, "end_offset": 160, "user": 1}, {"label": 4, "start_offset": 161, "end_offset": 165, "user": 1}, {"label": 4, "start_offset": 166, "end_offset": 167, "user": 1}, {"label": 4, "start_offset": 168, "end_offset": 175, "user": 1}, {"label": 2, "start_offset": 176, "end_offset": 198, "user": 1}, {"label": 4, "start_offset": 199, "end_offset": 201, "user": 1}, {"label": 2, "start_offset": 202, "end_offset": 211, "user": 1}, {"label": 2, "start_offset": 131, "end_offset": 138, "user": 1}], "meta": {}}
{"id": 56, "text": "bmm, tensordot, and einsum all do some sort of reshape followed by one or more mms. This makes doing reducing over arbitrary dimensions of large expanded/unfolded tensors slow, as the reshapes copy the data.", "annotations": [{"label": 2, "start_offset": 0, "end_offset": 3, "user": 1}, {"label": 2, "start_offset": 5, "end_offset": 14, "user": 1}, {"label": 4, "start_offset": 16, "end_offset": 19, "user": 1}, {"label": 2, "start_offset": 20, "end_offset": 26, "user": 1}, {"label": 4, "start_offset": 27, "end_offset": 30, "user": 1}, {"label": 4, "start_offset": 31, "end_offset": 33, "user": 1}, {"label": 4, "start_offset": 34, "end_offset": 38, "user": 1}, {"label": 4, "start_offset": 39, "end_offset": 43, "user": 1}, {"label": 4, "start_offset": 44, "end_offset": 46, "user": 1}, {"label": 2, "start_offset": 47, "end_offset": 54, "user": 1}, {"label": 4, "start_offset": 55, "end_offset": 63, "user": 1}, {"label": 4, "start_offset": 64, "end_offset": 66, "user": 1}, {"label": 4, "start_offset": 67, "end_offset": 70, "user": 1}, {"label": 4, "start_offset": 71, "end_offset": 73, "user": 1}, {"label": 4, "start_offset": 74, "end_offset": 78, "user": 1}, {"label": 2, "start_offset": 79, "end_offset": 82, "user": 1}, {"label": 4, "start_offset": 84, "end_offset": 88, "user": 1}, {"label": 4, "start_offset": 89, "end_offset": 94, "user": 1}, {"label": 4, "start_offset": 95, "end_offset": 100, "user": 1}, {"label": 4, "start_offset": 101, "end_offset": 109, "user": 1}, {"label": 4, "start_offset": 110, "end_offset": 114, "user": 1}, {"label": 4, "start_offset": 115, "end_offset": 124, "user": 1}, {"label": 4, "start_offset": 125, "end_offset": 135, "user": 1}, {"label": 4, "start_offset": 136, "end_offset": 138, "user": 1}, {"label": 4, "start_offset": 139, "end_offset": 144, "user": 1}, {"label": 4, "start_offset": 145, "end_offset": 162, "user": 1}, {"label": 4, "start_offset": 163, "end_offset": 170, "user": 1}, {"label": 4, "start_offset": 171, "end_offset": 175, "user": 1}, {"label": 4, "start_offset": 177, "end_offset": 179, "user": 1}, {"label": 4, "start_offset": 180, "end_offset": 183, "user": 1}, {"label": 4, "start_offset": 184, "end_offset": 192, "user": 1}, {"label": 4, "start_offset": 193, "end_offset": 197, "user": 1}, {"label": 4, "start_offset": 198, "end_offset": 201, "user": 1}, {"label": 4, "start_offset": 202, "end_offset": 206, "user": 1}], "meta": {}}
{"id": 57, "text": "After setting do_constant_folding=True default for run_debug_test and run_actual_test we get much more:", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 5, "user": 1}, {"label": 4, "start_offset": 6, "end_offset": 13, "user": 1}, {"label": 2, "start_offset": 14, "end_offset": 38, "user": 1}, {"label": 4, "start_offset": 39, "end_offset": 46, "user": 1}, {"label": 4, "start_offset": 47, "end_offset": 50, "user": 1}, {"label": 2, "start_offset": 51, "end_offset": 65, "user": 1}, {"label": 4, "start_offset": 66, "end_offset": 69, "user": 1}, {"label": 2, "start_offset": 70, "end_offset": 85, "user": 1}, {"label": 4, "start_offset": 86, "end_offset": 88, "user": 1}, {"label": 4, "start_offset": 89, "end_offset": 92, "user": 1}, {"label": 4, "start_offset": 93, "end_offset": 97, "user": 1}, {"label": 4, "start_offset": 98, "end_offset": 102, "user": 1}], "meta": {}}
{"id": 58, "text": "In torch.onnx, a function should be created to take the ONNX model and outputs a Pytorch model.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 2, "user": 1}, {"label": 2, "start_offset": 3, "end_offset": 14, "user": 1}, {"label": 4, "start_offset": 15, "end_offset": 16, "user": 1}, {"label": 4, "start_offset": 17, "end_offset": 25, "user": 1}, {"label": 4, "start_offset": 26, "end_offset": 32, "user": 1}, {"label": 4, "start_offset": 33, "end_offset": 35, "user": 1}, {"label": 4, "start_offset": 36, "end_offset": 43, "user": 1}, {"label": 4, "start_offset": 44, "end_offset": 46, "user": 1}, {"label": 4, "start_offset": 47, "end_offset": 51, "user": 1}, {"label": 4, "start_offset": 52, "end_offset": 55, "user": 1}, {"label": 4, "start_offset": 56, "end_offset": 60, "user": 1}, {"label": 4, "start_offset": 61, "end_offset": 66, "user": 1}, {"label": 4, "start_offset": 67, "end_offset": 70, "user": 1}, {"label": 4, "start_offset": 71, "end_offset": 78, "user": 1}, {"label": 4, "start_offset": 79, "end_offset": 80, "user": 1}, {"label": 4, "start_offset": 81, "end_offset": 88, "user": 1}, {"label": 4, "start_offset": 89, "end_offset": 94, "user": 1}], "meta": {}}
{"id": 59, "text": "I have tried benchmarking with both torch.backends.cudnn.benchmark set to False and True", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 1, "user": 1}, {"label": 4, "start_offset": 2, "end_offset": 6, "user": 1}, {"label": 4, "start_offset": 7, "end_offset": 12, "user": 1}, {"label": 4, "start_offset": 13, "end_offset": 25, "user": 1}, {"label": 4, "start_offset": 26, "end_offset": 30, "user": 1}, {"label": 4, "start_offset": 31, "end_offset": 35, "user": 1}, {"label": 2, "start_offset": 36, "end_offset": 66, "user": 1}, {"label": 4, "start_offset": 67, "end_offset": 70, "user": 1}, {"label": 4, "start_offset": 71, "end_offset": 73, "user": 1}, {"label": 2, "start_offset": 74, "end_offset": 79, "user": 1}, {"label": 4, "start_offset": 80, "end_offset": 83, "user": 1}, {"label": 2, "start_offset": 84, "end_offset": 88, "user": 1}], "meta": {}}
{"id": 60, "text": "From this intermediate information from torch.trace.graph() we can find that (0.229 / 0.5) and (0.485 - 0.5) / 0.5 are both translated to contant with double type(%591 and %593).", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 4, "user": 1}, {"label": 4, "start_offset": 5, "end_offset": 9, "user": 1}, {"label": 4, "start_offset": 10, "end_offset": 22, "user": 1}, {"label": 4, "start_offset": 23, "end_offset": 34, "user": 1}, {"label": 4, "start_offset": 35, "end_offset": 39, "user": 1}, {"label": 2, "start_offset": 40, "end_offset": 59, "user": 1}, {"label": 4, "start_offset": 60, "end_offset": 62, "user": 1}, {"label": 4, "start_offset": 63, "end_offset": 66, "user": 1}, {"label": 4, "start_offset": 67, "end_offset": 71, "user": 1}, {"label": 4, "start_offset": 72, "end_offset": 76, "user": 1}, {"label": 4, "start_offset": 77, "end_offset": 90, "user": 1}, {"label": 4, "start_offset": 91, "end_offset": 94, "user": 1}, {"label": 4, "start_offset": 95, "end_offset": 108, "user": 1}, {"label": 4, "start_offset": 111, "end_offset": 114, "user": 1}, {"label": 4, "start_offset": 115, "end_offset": 118, "user": 1}, {"label": 4, "start_offset": 119, "end_offset": 123, "user": 1}, {"label": 4, "start_offset": 124, "end_offset": 134, "user": 1}, {"label": 4, "start_offset": 135, "end_offset": 137, "user": 1}, {"label": 4, "start_offset": 138, "end_offset": 145, "user": 1}, {"label": 4, "start_offset": 146, "end_offset": 150, "user": 1}, {"label": 4, "start_offset": 151, "end_offset": 157, "user": 1}, {"label": 4, "start_offset": 158, "end_offset": 167, "user": 1}, {"label": 4, "start_offset": 168, "end_offset": 171, "user": 1}, {"label": 4, "start_offset": 172, "end_offset": 176, "user": 1}], "meta": {}}
{"id": 61, "text": "Support the argument format torch.einsum(op0, sublist0, op1, sublist1, ..., [sublistout]). It would allow the users to use more than 26 tensors (i.e. the number of lower case letters) in Einstein Summation.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 7, "user": 1}, {"label": 4, "start_offset": 8, "end_offset": 11, "user": 1}, {"label": 4, "start_offset": 12, "end_offset": 20, "user": 1}, {"label": 4, "start_offset": 21, "end_offset": 27, "user": 1}, {"label": 2, "start_offset": 28, "end_offset": 45, "user": 1}, {"label": 3, "start_offset": 46, "end_offset": 55, "user": 1}, {"label": 3, "start_offset": 56, "end_offset": 60, "user": 1}, {"label": 3, "start_offset": 61, "end_offset": 70, "user": 1}, {"label": 3, "start_offset": 71, "end_offset": 75, "user": 1}, {"label": 3, "start_offset": 76, "end_offset": 89, "user": 1}, {"label": 4, "start_offset": 91, "end_offset": 93, "user": 1}, {"label": 4, "start_offset": 94, "end_offset": 99, "user": 1}, {"label": 4, "start_offset": 100, "end_offset": 105, "user": 1}, {"label": 4, "start_offset": 106, "end_offset": 109, "user": 1}, {"label": 4, "start_offset": 110, "end_offset": 115, "user": 1}, {"label": 4, "start_offset": 116, "end_offset": 118, "user": 1}, {"label": 4, "start_offset": 119, "end_offset": 122, "user": 1}, {"label": 4, "start_offset": 123, "end_offset": 127, "user": 1}, {"label": 4, "start_offset": 128, "end_offset": 132, "user": 1}, {"label": 4, "start_offset": 133, "end_offset": 135, "user": 1}, {"label": 4, "start_offset": 136, "end_offset": 143, "user": 1}, {"label": 4, "start_offset": 145, "end_offset": 149, "user": 1}, {"label": 4, "start_offset": 150, "end_offset": 153, "user": 1}, {"label": 4, "start_offset": 154, "end_offset": 160, "user": 1}, {"label": 4, "start_offset": 161, "end_offset": 163, "user": 1}, {"label": 4, "start_offset": 164, "end_offset": 169, "user": 1}, {"label": 4, "start_offset": 170, "end_offset": 174, "user": 1}, {"label": 4, "start_offset": 175, "end_offset": 182, "user": 1}, {"label": 4, "start_offset": 184, "end_offset": 186, "user": 1}, {"label": 4, "start_offset": 187, "end_offset": 195, "user": 1}, {"label": 4, "start_offset": 196, "end_offset": 205, "user": 1}], "meta": {}}
{"id": 62, "text": "We would accept a PR that enhances einsum with this new mode of operation.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 2, "user": 1}, {"label": 4, "start_offset": 3, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 15, "user": 1}, {"label": 4, "start_offset": 16, "end_offset": 17, "user": 1}, {"label": 4, "start_offset": 18, "end_offset": 20, "user": 1}, {"label": 4, "start_offset": 21, "end_offset": 25, "user": 1}, {"label": 4, "start_offset": 26, "end_offset": 34, "user": 1}, {"label": 2, "start_offset": 35, "end_offset": 41, "user": 1}, {"label": 4, "start_offset": 42, "end_offset": 46, "user": 1}, {"label": 4, "start_offset": 47, "end_offset": 51, "user": 1}, {"label": 4, "start_offset": 52, "end_offset": 55, "user": 1}, {"label": 4, "start_offset": 56, "end_offset": 60, "user": 1}, {"label": 4, "start_offset": 61, "end_offset": 63, "user": 1}, {"label": 4, "start_offset": 64, "end_offset": 73, "user": 1}], "meta": {}}
{"id": 63, "text": "I'm not sure if the existing pytorch implementations are efficient as they take considerably more time to run than nn.Conv2d.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 3, "user": 1}, {"label": 4, "start_offset": 4, "end_offset": 7, "user": 1}, {"label": 4, "start_offset": 8, "end_offset": 12, "user": 1}, {"label": 4, "start_offset": 13, "end_offset": 15, "user": 1}, {"label": 4, "start_offset": 16, "end_offset": 19, "user": 1}, {"label": 4, "start_offset": 20, "end_offset": 28, "user": 1}, {"label": 4, "start_offset": 29, "end_offset": 36, "user": 1}, {"label": 4, "start_offset": 37, "end_offset": 52, "user": 1}, {"label": 4, "start_offset": 53, "end_offset": 56, "user": 1}, {"label": 4, "start_offset": 57, "end_offset": 66, "user": 1}, {"label": 4, "start_offset": 67, "end_offset": 69, "user": 1}, {"label": 4, "start_offset": 70, "end_offset": 74, "user": 1}, {"label": 4, "start_offset": 75, "end_offset": 79, "user": 1}, {"label": 4, "start_offset": 80, "end_offset": 92, "user": 1}, {"label": 4, "start_offset": 93, "end_offset": 97, "user": 1}, {"label": 4, "start_offset": 98, "end_offset": 102, "user": 1}, {"label": 4, "start_offset": 103, "end_offset": 105, "user": 1}, {"label": 4, "start_offset": 106, "end_offset": 109, "user": 1}, {"label": 4, "start_offset": 110, "end_offset": 114, "user": 1}, {"label": 2, "start_offset": 115, "end_offset": 124, "user": 1}], "meta": {}}
{"id": 64, "text": "To sum up, it would be awesome if you guys could create nn.GConv2d() for group-equivariant convolutions on at least the two groups mentioned before.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 2, "user": 1}, {"label": 4, "start_offset": 3, "end_offset": 6, "user": 1}, {"label": 4, "start_offset": 7, "end_offset": 9, "user": 1}, {"label": 4, "start_offset": 11, "end_offset": 13, "user": 1}, {"label": 4, "start_offset": 14, "end_offset": 19, "user": 1}, {"label": 4, "start_offset": 20, "end_offset": 22, "user": 1}, {"label": 4, "start_offset": 23, "end_offset": 30, "user": 1}, {"label": 4, "start_offset": 31, "end_offset": 33, "user": 1}, {"label": 4, "start_offset": 34, "end_offset": 37, "user": 1}, {"label": 4, "start_offset": 38, "end_offset": 42, "user": 1}, {"label": 4, "start_offset": 43, "end_offset": 48, "user": 1}, {"label": 4, "start_offset": 49, "end_offset": 55, "user": 1}, {"label": 2, "start_offset": 56, "end_offset": 68, "user": 1}, {"label": 4, "start_offset": 69, "end_offset": 72, "user": 1}, {"label": 4, "start_offset": 73, "end_offset": 90, "user": 1}, {"label": 4, "start_offset": 91, "end_offset": 103, "user": 1}, {"label": 4, "start_offset": 104, "end_offset": 106, "user": 1}, {"label": 4, "start_offset": 107, "end_offset": 109, "user": 1}, {"label": 4, "start_offset": 110, "end_offset": 115, "user": 1}, {"label": 4, "start_offset": 116, "end_offset": 119, "user": 1}, {"label": 4, "start_offset": 120, "end_offset": 123, "user": 1}, {"label": 4, "start_offset": 124, "end_offset": 130, "user": 1}, {"label": 4, "start_offset": 131, "end_offset": 140, "user": 1}, {"label": 4, "start_offset": 141, "end_offset": 147, "user": 1}], "meta": {}}
{"id": 65, "text": "Hi, I try convert FCOS model to onnx. The self.model output type is BoxList. I add the convert code after the \"predictions = self.model(image_list)\".", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 2, "user": 1}, {"label": 4, "start_offset": 4, "end_offset": 5, "user": 1}, {"label": 4, "start_offset": 6, "end_offset": 9, "user": 1}, {"label": 4, "start_offset": 10, "end_offset": 17, "user": 1}, {"label": 4, "start_offset": 18, "end_offset": 22, "user": 1}, {"label": 4, "start_offset": 23, "end_offset": 28, "user": 1}, {"label": 4, "start_offset": 29, "end_offset": 31, "user": 1}, {"label": 4, "start_offset": 32, "end_offset": 36, "user": 1}, {"label": 4, "start_offset": 38, "end_offset": 41, "user": 1}, {"label": 2, "start_offset": 42, "end_offset": 59, "user": 1}, {"label": 4, "start_offset": 60, "end_offset": 64, "user": 1}, {"label": 4, "start_offset": 65, "end_offset": 67, "user": 1}, {"label": 2, "start_offset": 68, "end_offset": 75, "user": 1}, {"label": 4, "start_offset": 77, "end_offset": 78, "user": 1}, {"label": 4, "start_offset": 79, "end_offset": 82, "user": 1}, {"label": 4, "start_offset": 83, "end_offset": 86, "user": 1}, {"label": 4, "start_offset": 87, "end_offset": 94, "user": 1}, {"label": 4, "start_offset": 95, "end_offset": 99, "user": 1}, {"label": 4, "start_offset": 100, "end_offset": 105, "user": 1}, {"label": 4, "start_offset": 106, "end_offset": 109, "user": 1}, {"label": 2, "start_offset": 111, "end_offset": 122, "user": 1}, {"label": 3, "start_offset": 123, "end_offset": 124, "user": 1}, {"label": 3, "start_offset": 125, "end_offset": 147, "user": 1}], "meta": {}}
{"id": 66, "text": "The code have an error, when the code runing in the \"torch.onnx.export()\"", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 3, "user": 1}, {"label": 4, "start_offset": 4, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 13, "user": 1}, {"label": 4, "start_offset": 14, "end_offset": 16, "user": 1}, {"label": 4, "start_offset": 17, "end_offset": 22, "user": 1}, {"label": 4, "start_offset": 24, "end_offset": 28, "user": 1}, {"label": 4, "start_offset": 29, "end_offset": 32, "user": 1}, {"label": 4, "start_offset": 33, "end_offset": 37, "user": 1}, {"label": 4, "start_offset": 38, "end_offset": 44, "user": 1}, {"label": 4, "start_offset": 45, "end_offset": 47, "user": 1}, {"label": 4, "start_offset": 48, "end_offset": 51, "user": 1}, {"label": 2, "start_offset": 53, "end_offset": 72, "user": 1}], "meta": {}}
{"id": 67, "text": "Move reduce_add and reduce_add_coalesced in torch/cuda/comm.py to C++.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 4, "user": 1}, {"label": 2, "start_offset": 5, "end_offset": 15, "user": 1}, {"label": 4, "start_offset": 16, "end_offset": 19, "user": 1}, {"label": 2, "start_offset": 20, "end_offset": 40, "user": 1}, {"label": 4, "start_offset": 41, "end_offset": 43, "user": 1}, {"label": 4, "start_offset": 44, "end_offset": 62, "user": 1}, {"label": 4, "start_offset": 63, "end_offset": 65, "user": 1}, {"label": 4, "start_offset": 66, "end_offset": 69, "user": 1}], "meta": {}}
{"id": 68, "text": "Move Broadcast and ReduceAddCoalesced from torch/nn/parallel/_functions.py to C++.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 4, "user": 1}, {"label": 2, "start_offset": 5, "end_offset": 14, "user": 1}, {"label": 4, "start_offset": 15, "end_offset": 18, "user": 1}, {"label": 2, "start_offset": 19, "end_offset": 37, "user": 1}, {"label": 4, "start_offset": 38, "end_offset": 42, "user": 1}, {"label": 4, "start_offset": 43, "end_offset": 74, "user": 1}, {"label": 4, "start_offset": 75, "end_offset": 77, "user": 1}, {"label": 4, "start_offset": 78, "end_offset": 81, "user": 1}], "meta": {}}
{"id": 69, "text": "Make C++ data parallel use ReduceAddCoalesced.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 4, "user": 1}, {"label": 4, "start_offset": 5, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 13, "user": 1}, {"label": 4, "start_offset": 14, "end_offset": 22, "user": 1}, {"label": 4, "start_offset": 23, "end_offset": 26, "user": 1}, {"label": 2, "start_offset": 27, "end_offset": 45, "user": 1}], "meta": {}}
{"id": 70, "text": "Append scalar using add_scalar into self.scalar_dict in SummaryWriter class.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 6, "user": 1}, {"label": 4, "start_offset": 7, "end_offset": 13, "user": 1}, {"label": 4, "start_offset": 14, "end_offset": 19, "user": 1}, {"label": 2, "start_offset": 20, "end_offset": 30, "user": 1}, {"label": 4, "start_offset": 31, "end_offset": 35, "user": 1}, {"label": 2, "start_offset": 36, "end_offset": 52, "user": 1}, {"label": 4, "start_offset": 53, "end_offset": 55, "user": 1}, {"label": 2, "start_offset": 56, "end_offset": 69, "user": 1}, {"label": 4, "start_offset": 70, "end_offset": 75, "user": 1}], "meta": {}}
{"id": 71, "text": "tensor.pin_memory() always asks for a context on the current device. This means that even if you use torch.device('cuda:1') everywhere in the program, a simple DataLoader(..., pin_memory=True) will create a context on GPU 0.", "annotations": [{"label": 2, "start_offset": 0, "end_offset": 19, "user": 1}, {"label": 4, "start_offset": 20, "end_offset": 26, "user": 1}, {"label": 4, "start_offset": 27, "end_offset": 31, "user": 1}, {"label": 4, "start_offset": 32, "end_offset": 35, "user": 1}, {"label": 4, "start_offset": 36, "end_offset": 37, "user": 1}, {"label": 4, "start_offset": 38, "end_offset": 45, "user": 1}, {"label": 4, "start_offset": 46, "end_offset": 48, "user": 1}, {"label": 4, "start_offset": 49, "end_offset": 52, "user": 1}, {"label": 4, "start_offset": 53, "end_offset": 60, "user": 1}, {"label": 4, "start_offset": 61, "end_offset": 67, "user": 1}, {"label": 4, "start_offset": 69, "end_offset": 73, "user": 1}, {"label": 4, "start_offset": 74, "end_offset": 79, "user": 1}, {"label": 4, "start_offset": 80, "end_offset": 84, "user": 1}, {"label": 4, "start_offset": 85, "end_offset": 89, "user": 1}, {"label": 4, "start_offset": 90, "end_offset": 92, "user": 1}, {"label": 4, "start_offset": 93, "end_offset": 96, "user": 1}, {"label": 4, "start_offset": 97, "end_offset": 100, "user": 1}, {"label": 2, "start_offset": 101, "end_offset": 123, "user": 1}, {"label": 4, "start_offset": 124, "end_offset": 134, "user": 1}, {"label": 4, "start_offset": 135, "end_offset": 137, "user": 1}, {"label": 4, "start_offset": 138, "end_offset": 141, "user": 1}, {"label": 4, "start_offset": 142, "end_offset": 149, "user": 1}, {"label": 4, "start_offset": 151, "end_offset": 152, "user": 1}, {"label": 4, "start_offset": 153, "end_offset": 159, "user": 1}, {"label": 2, "start_offset": 160, "end_offset": 175, "user": 1}, {"label": 3, "start_offset": 176, "end_offset": 192, "user": 1}, {"label": 4, "start_offset": 193, "end_offset": 197, "user": 1}, {"label": 4, "start_offset": 198, "end_offset": 204, "user": 1}, {"label": 4, "start_offset": 205, "end_offset": 206, "user": 1}, {"label": 4, "start_offset": 207, "end_offset": 214, "user": 1}, {"label": 4, "start_offset": 215, "end_offset": 217, "user": 1}, {"label": 4, "start_offset": 218, "end_offset": 221, "user": 1}, {"label": 4, "start_offset": 222, "end_offset": 223, "user": 1}], "meta": {}}
{"id": 72, "text": "A little dig into cudaHostAlloc and our THCCachingHostAllocator tells me that:  We allocate pinned memory with cudaHostAlloc(ptr, size, cudaHostAllocDefault).  Such allocated pointers can be directly used by any device, regardless of the current device at the time of allocation, since we assume unified addressing.  Therefore, I wonder, instead of always asking for a context on the current device, if tensor.pin_memory() should just grab any CUDA context if exists.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 1, "user": 1}, {"label": 4, "start_offset": 2, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 12, "user": 1}, {"label": 4, "start_offset": 13, "end_offset": 17, "user": 1}, {"label": 2, "start_offset": 18, "end_offset": 31, "user": 1}, {"label": 4, "start_offset": 32, "end_offset": 35, "user": 1}, {"label": 4, "start_offset": 36, "end_offset": 39, "user": 1}, {"label": 2, "start_offset": 40, "end_offset": 63, "user": 1}, {"label": 4, "start_offset": 64, "end_offset": 69, "user": 1}, {"label": 4, "start_offset": 70, "end_offset": 72, "user": 1}, {"label": 4, "start_offset": 73, "end_offset": 77, "user": 1}, {"label": 4, "start_offset": 80, "end_offset": 82, "user": 1}, {"label": 4, "start_offset": 83, "end_offset": 91, "user": 1}, {"label": 4, "start_offset": 92, "end_offset": 98, "user": 1}, {"label": 4, "start_offset": 99, "end_offset": 105, "user": 1}, {"label": 4, "start_offset": 106, "end_offset": 110, "user": 1}, {"label": 2, "start_offset": 111, "end_offset": 129, "user": 1}, {"label": 3, "start_offset": 130, "end_offset": 135, "user": 1}, {"label": 3, "start_offset": 136, "end_offset": 157, "user": 1}, {"label": 4, "start_offset": 160, "end_offset": 164, "user": 1}, {"label": 4, "start_offset": 165, "end_offset": 174, "user": 1}, {"label": 4, "start_offset": 175, "end_offset": 183, "user": 1}, {"label": 4, "start_offset": 184, "end_offset": 187, "user": 1}, {"label": 4, "start_offset": 188, "end_offset": 190, "user": 1}, {"label": 4, "start_offset": 191, "end_offset": 199, "user": 1}, {"label": 4, "start_offset": 200, "end_offset": 204, "user": 1}, {"label": 4, "start_offset": 205, "end_offset": 207, "user": 1}, {"label": 4, "start_offset": 208, "end_offset": 211, "user": 1}, {"label": 4, "start_offset": 212, "end_offset": 218, "user": 1}, {"label": 4, "start_offset": 220, "end_offset": 230, "user": 1}, {"label": 4, "start_offset": 231, "end_offset": 233, "user": 1}, {"label": 4, "start_offset": 234, "end_offset": 237, "user": 1}, {"label": 4, "start_offset": 238, "end_offset": 245, "user": 1}, {"label": 4, "start_offset": 246, "end_offset": 252, "user": 1}, {"label": 4, "start_offset": 253, "end_offset": 255, "user": 1}, {"label": 4, "start_offset": 256, "end_offset": 259, "user": 1}, {"label": 4, "start_offset": 260, "end_offset": 264, "user": 1}, {"label": 4, "start_offset": 265, "end_offset": 267, "user": 1}, {"label": 4, "start_offset": 268, "end_offset": 278, "user": 1}, {"label": 4, "start_offset": 280, "end_offset": 285, "user": 1}, {"label": 4, "start_offset": 286, "end_offset": 288, "user": 1}, {"label": 4, "start_offset": 289, "end_offset": 295, "user": 1}, {"label": 4, "start_offset": 296, "end_offset": 303, "user": 1}, {"label": 4, "start_offset": 304, "end_offset": 314, "user": 1}, {"label": 4, "start_offset": 317, "end_offset": 326, "user": 1}, {"label": 4, "start_offset": 328, "end_offset": 329, "user": 1}, {"label": 4, "start_offset": 330, "end_offset": 336, "user": 1}, {"label": 4, "start_offset": 338, "end_offset": 345, "user": 1}, {"label": 4, "start_offset": 346, "end_offset": 348, "user": 1}, {"label": 4, "start_offset": 349, "end_offset": 355, "user": 1}, {"label": 4, "start_offset": 356, "end_offset": 362, "user": 1}, {"label": 4, "start_offset": 363, "end_offset": 366, "user": 1}, {"label": 4, "start_offset": 367, "end_offset": 368, "user": 1}, {"label": 4, "start_offset": 369, "end_offset": 376, "user": 1}, {"label": 4, "start_offset": 377, "end_offset": 379, "user": 1}, {"label": 4, "start_offset": 380, "end_offset": 383, "user": 1}, {"label": 4, "start_offset": 384, "end_offset": 391, "user": 1}, {"label": 4, "start_offset": 392, "end_offset": 398, "user": 1}, {"label": 4, "start_offset": 400, "end_offset": 402, "user": 1}, {"label": 2, "start_offset": 403, "end_offset": 422, "user": 1}, {"label": 4, "start_offset": 430, "end_offset": 434, "user": 1}, {"label": 4, "start_offset": 423, "end_offset": 429, "user": 1}, {"label": 4, "start_offset": 435, "end_offset": 439, "user": 1}, {"label": 4, "start_offset": 440, "end_offset": 443, "user": 1}, {"label": 4, "start_offset": 444, "end_offset": 448, "user": 1}, {"label": 4, "start_offset": 449, "end_offset": 456, "user": 1}, {"label": 4, "start_offset": 457, "end_offset": 459, "user": 1}, {"label": 4, "start_offset": 460, "end_offset": 466, "user": 1}], "meta": {}}
{"id": 73, "text": "One way is to use cuDevicePrimaryCtxGetState, but maybe just looking at the caching allocator is enough.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 3, "user": 1}, {"label": 4, "start_offset": 4, "end_offset": 7, "user": 1}, {"label": 4, "start_offset": 8, "end_offset": 10, "user": 1}, {"label": 4, "start_offset": 11, "end_offset": 13, "user": 1}, {"label": 4, "start_offset": 14, "end_offset": 17, "user": 1}, {"label": 2, "start_offset": 18, "end_offset": 44, "user": 1}, {"label": 4, "start_offset": 46, "end_offset": 49, "user": 1}, {"label": 4, "start_offset": 50, "end_offset": 55, "user": 1}, {"label": 4, "start_offset": 56, "end_offset": 60, "user": 1}, {"label": 4, "start_offset": 61, "end_offset": 68, "user": 1}, {"label": 4, "start_offset": 69, "end_offset": 71, "user": 1}, {"label": 4, "start_offset": 72, "end_offset": 75, "user": 1}, {"label": 4, "start_offset": 76, "end_offset": 83, "user": 1}, {"label": 4, "start_offset": 84, "end_offset": 93, "user": 1}, {"label": 4, "start_offset": 94, "end_offset": 96, "user": 1}, {"label": 4, "start_offset": 97, "end_offset": 103, "user": 1}], "meta": {}}
{"id": 74, "text": "I got an error when use jit.script on some new layers(implemented in c++)", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 1, "user": 1}, {"label": 4, "start_offset": 2, "end_offset": 5, "user": 1}, {"label": 4, "start_offset": 6, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 14, "user": 1}, {"label": 4, "start_offset": 15, "end_offset": 19, "user": 1}, {"label": 4, "start_offset": 20, "end_offset": 23, "user": 1}, {"label": 2, "start_offset": 24, "end_offset": 34, "user": 1}, {"label": 4, "start_offset": 35, "end_offset": 37, "user": 1}, {"label": 4, "start_offset": 38, "end_offset": 42, "user": 1}, {"label": 4, "start_offset": 43, "end_offset": 46, "user": 1}, {"label": 4, "start_offset": 47, "end_offset": 53, "user": 1}, {"label": 4, "start_offset": 54, "end_offset": 65, "user": 1}, {"label": 4, "start_offset": 66, "end_offset": 68, "user": 1}, {"label": 4, "start_offset": 69, "end_offset": 72, "user": 1}], "meta": {}}
{"id": 75, "text": "I am trying to use torch.distributions.MultivariateNormal to sample some normal distributed noise.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 1, "user": 1}, {"label": 4, "start_offset": 2, "end_offset": 4, "user": 1}, {"label": 4, "start_offset": 5, "end_offset": 11, "user": 1}, {"label": 4, "start_offset": 12, "end_offset": 14, "user": 1}, {"label": 4, "start_offset": 15, "end_offset": 18, "user": 1}, {"label": 2, "start_offset": 19, "end_offset": 57, "user": 1}, {"label": 4, "start_offset": 58, "end_offset": 60, "user": 1}, {"label": 4, "start_offset": 61, "end_offset": 67, "user": 1}, {"label": 4, "start_offset": 68, "end_offset": 72, "user": 1}, {"label": 4, "start_offset": 73, "end_offset": 79, "user": 1}, {"label": 4, "start_offset": 80, "end_offset": 91, "user": 1}, {"label": 4, "start_offset": 92, "end_offset": 97, "user": 1}], "meta": {}}
{"id": 76, "text": "Ambiguous torch.Tensor int vs float comparison", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 9, "user": 1}, {"label": 2, "start_offset": 10, "end_offset": 22, "user": 1}, {"label": 3, "start_offset": 23, "end_offset": 26, "user": 1}, {"label": 2, "start_offset": 30, "end_offset": 35, "user": 1}, {"label": 4, "start_offset": 27, "end_offset": 29, "user": 1}, {"label": 4, "start_offset": 36, "end_offset": 46, "user": 1}], "meta": {}}
{"id": 77, "text": "I'm currently working on a big model and would like to use torch.nn.DataParallel to speed up training.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 3, "user": 1}, {"label": 4, "start_offset": 4, "end_offset": 13, "user": 1}, {"label": 4, "start_offset": 14, "end_offset": 21, "user": 1}, {"label": 4, "start_offset": 22, "end_offset": 24, "user": 1}, {"label": 4, "start_offset": 25, "end_offset": 26, "user": 1}, {"label": 4, "start_offset": 27, "end_offset": 30, "user": 1}, {"label": 4, "start_offset": 31, "end_offset": 36, "user": 1}, {"label": 4, "start_offset": 37, "end_offset": 40, "user": 1}, {"label": 4, "start_offset": 41, "end_offset": 46, "user": 1}, {"label": 4, "start_offset": 47, "end_offset": 51, "user": 1}, {"label": 4, "start_offset": 52, "end_offset": 54, "user": 1}, {"label": 4, "start_offset": 55, "end_offset": 58, "user": 1}, {"label": 2, "start_offset": 59, "end_offset": 80, "user": 1}, {"label": 4, "start_offset": 81, "end_offset": 83, "user": 1}, {"label": 4, "start_offset": 84, "end_offset": 89, "user": 1}, {"label": 4, "start_offset": 90, "end_offset": 92, "user": 1}, {"label": 4, "start_offset": 93, "end_offset": 101, "user": 1}], "meta": {}}
{"id": 78, "text": "Backprop through backprop of torch.nn.functional.unfold.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 16, "user": 1}, {"label": 4, "start_offset": 17, "end_offset": 25, "user": 1}, {"label": 4, "start_offset": 26, "end_offset": 28, "user": 1}, {"label": 2, "start_offset": 29, "end_offset": 55, "user": 1}], "meta": {}}
{"id": 79, "text": "PackedSequence's sorted_indices is not put on cuda when .to('cuda') is called, but .to(device='cuda')", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 16, "user": 1}, {"label": 2, "start_offset": 17, "end_offset": 31, "user": 1}, {"label": 4, "start_offset": 32, "end_offset": 34, "user": 1}, {"label": 4, "start_offset": 35, "end_offset": 38, "user": 1}, {"label": 4, "start_offset": 39, "end_offset": 42, "user": 1}, {"label": 4, "start_offset": 43, "end_offset": 45, "user": 1}, {"label": 4, "start_offset": 46, "end_offset": 50, "user": 1}, {"label": 4, "start_offset": 51, "end_offset": 55, "user": 1}, {"label": 2, "start_offset": 56, "end_offset": 67, "user": 1}, {"label": 4, "start_offset": 68, "end_offset": 70, "user": 1}, {"label": 4, "start_offset": 71, "end_offset": 77, "user": 1}, {"label": 4, "start_offset": 79, "end_offset": 82, "user": 1}, {"label": 2, "start_offset": 83, "end_offset": 101, "user": 1}], "meta": {}}
{"id": 80, "text": "Maybe it should be lambda t: t.to(*args, **kwargs) as the previous line", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 5, "user": 1}, {"label": 4, "start_offset": 6, "end_offset": 8, "user": 1}, {"label": 4, "start_offset": 9, "end_offset": 15, "user": 1}, {"label": 4, "start_offset": 16, "end_offset": 18, "user": 1}, {"label": 2, "start_offset": 19, "end_offset": 25, "user": 1}, {"label": 3, "start_offset": 26, "end_offset": 28, "user": 1}, {"label": 3, "start_offset": 29, "end_offset": 40, "user": 1}, {"label": 3, "start_offset": 41, "end_offset": 50, "user": 1}, {"label": 4, "start_offset": 51, "end_offset": 53, "user": 1}, {"label": 4, "start_offset": 54, "end_offset": 57, "user": 1}, {"label": 4, "start_offset": 58, "end_offset": 66, "user": 1}, {"label": 4, "start_offset": 67, "end_offset": 71, "user": 1}], "meta": {}}
{"id": 81, "text": "torch.lu_solve gives an unintuitive error message when the inputs are not batched", "annotations": [{"label": 2, "start_offset": 0, "end_offset": 14, "user": 1}, {"label": 4, "start_offset": 15, "end_offset": 20, "user": 1}, {"label": 4, "start_offset": 21, "end_offset": 23, "user": 1}, {"label": 4, "start_offset": 24, "end_offset": 35, "user": 1}, {"label": 4, "start_offset": 36, "end_offset": 41, "user": 1}, {"label": 4, "start_offset": 42, "end_offset": 49, "user": 1}, {"label": 4, "start_offset": 50, "end_offset": 54, "user": 1}, {"label": 4, "start_offset": 55, "end_offset": 58, "user": 1}, {"label": 4, "start_offset": 59, "end_offset": 65, "user": 1}, {"label": 4, "start_offset": 66, "end_offset": 69, "user": 1}, {"label": 4, "start_offset": 70, "end_offset": 73, "user": 1}, {"label": 4, "start_offset": 74, "end_offset": 81, "user": 1}], "meta": {}}
{"id": 82, "text": "In tensorflow keras, the input_tensors, output_tensors, output_shapes of class Node was a list in tensorflow 1.13.1, even if it only contains one tensor", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 2, "user": 1}, {"label": 2, "start_offset": 25, "end_offset": 38, "user": 1}, {"label": 2, "start_offset": 40, "end_offset": 54, "user": 1}, {"label": 2, "start_offset": 56, "end_offset": 69, "user": 1}, {"label": 2, "start_offset": 73, "end_offset": 78, "user": 1}, {"label": 3, "start_offset": 79, "end_offset": 83, "user": 1}, {"label": 4, "start_offset": 84, "end_offset": 87, "user": 1}, {"label": 4, "start_offset": 88, "end_offset": 89, "user": 1}, {"label": 4, "start_offset": 90, "end_offset": 94, "user": 1}, {"label": 4, "start_offset": 95, "end_offset": 97, "user": 1}, {"label": 4, "start_offset": 98, "end_offset": 108, "user": 1}, {"label": 4, "start_offset": 109, "end_offset": 115, "user": 1}, {"label": 4, "start_offset": 117, "end_offset": 121, "user": 1}, {"label": 4, "start_offset": 122, "end_offset": 124, "user": 1}, {"label": 4, "start_offset": 125, "end_offset": 127, "user": 1}, {"label": 4, "start_offset": 128, "end_offset": 132, "user": 1}, {"label": 4, "start_offset": 133, "end_offset": 141, "user": 1}, {"label": 4, "start_offset": 142, "end_offset": 145, "user": 1}, {"label": 4, "start_offset": 146, "end_offset": 152, "user": 1}, {"label": 4, "start_offset": 3, "end_offset": 13, "user": 1}, {"label": 4, "start_offset": 14, "end_offset": 19, "user": 1}, {"label": 4, "start_offset": 21, "end_offset": 24, "user": 1}, {"label": 4, "start_offset": 70, "end_offset": 72, "user": 1}], "meta": {}}
{"id": 83, "text": "I have a tf.data.Dataset that I want to write to tfrecord files. to do this, I currently use tf.python_io.TFRecordWriter to do this, but would like to use tf.data.experimental.TFRecordWriter, as it would be more efficient to also do the writing as part of the dataset graph execution.", "annotations": [{"label": 4, "start_offset": 0, "end_offset": 1, "user": 1}, {"label": 4, "start_offset": 2, "end_offset": 6, "user": 1}, {"label": 4, "start_offset": 7, "end_offset": 8, "user": 1}, {"label": 2, "start_offset": 9, "end_offset": 24, "user": 1}, {"label": 4, "start_offset": 25, "end_offset": 29, "user": 1}, {"label": 4, "start_offset": 30, "end_offset": 31, "user": 1}, {"label": 4, "start_offset": 32, "end_offset": 36, "user": 1}, {"label": 4, "start_offset": 37, "end_offset": 39, "user": 1}, {"label": 4, "start_offset": 40, "end_offset": 45, "user": 1}, {"label": 4, "start_offset": 46, "end_offset": 48, "user": 1}, {"label": 4, "start_offset": 49, "end_offset": 57, "user": 1}, {"label": 4, "start_offset": 58, "end_offset": 63, "user": 1}, {"label": 4, "start_offset": 65, "end_offset": 67, "user": 1}, {"label": 4, "start_offset": 68, "end_offset": 70, "user": 1}, {"label": 4, "start_offset": 71, "end_offset": 75, "user": 1}, {"label": 4, "start_offset": 77, "end_offset": 78, "user": 1}, {"label": 4, "start_offset": 79, "end_offset": 88, "user": 1}, {"label": 4, "start_offset": 89, "end_offset": 92, "user": 1}, {"label": 2, "start_offset": 93, "end_offset": 120, "user": 1}, {"label": 4, "start_offset": 121, "end_offset": 123, "user": 1}, {"label": 4, "start_offset": 124, "end_offset": 126, "user": 1}, {"label": 4, "start_offset": 127, "end_offset": 131, "user": 1}, {"label": 4, "start_offset": 133, "end_offset": 136, "user": 1}, {"label": 4, "start_offset": 137, "end_offset": 142, "user": 1}, {"label": 4, "start_offset": 143, "end_offset": 147, "user": 1}, {"label": 4, "start_offset": 148, "end_offset": 150, "user": 1}, {"label": 4, "start_offset": 151, "end_offset": 154, "user": 1}, {"label": 2, "start_offset": 155, "end_offset": 190, "user": 1}, {"label": 4, "start_offset": 192, "end_offset": 194, "user": 1}, {"label": 4, "start_offset": 195, "end_offset": 197, "user": 1}, {"label": 4, "start_offset": 198, "end_offset": 203, "user": 1}, {"label": 4, "start_offset": 204, "end_offset": 206, "user": 1}, {"label": 4, "start_offset": 207, "end_offset": 211, "user": 1}, {"label": 4, "start_offset": 212, "end_offset": 221, "user": 1}, {"label": 4, "start_offset": 222, "end_offset": 224, "user": 1}, {"label": 4, "start_offset": 225, "end_offset": 229, "user": 1}, {"label": 4, "start_offset": 230, "end_offset": 232, "user": 1}, {"label": 4, "start_offset": 233, "end_offset": 236, "user": 1}, {"label": 4, "start_offset": 237, "end_offset": 244, "user": 1}, {"label": 4, "start_offset": 245, "end_offset": 247, "user": 1}, {"label": 4, "start_offset": 248, "end_offset": 252, "user": 1}, {"label": 4, "start_offset": 253, "end_offset": 255, "user": 1}, {"label": 4, "start_offset": 256, "end_offset": 259, "user": 1}, {"label": 4, "start_offset": 260, "end_offset": 267, "user": 1}, {"label": 4, "start_offset": 268, "end_offset": 273, "user": 1}, {"label": 4, "start_offset": 274, "end_offset": 283, "user": 1}], "meta": {}}
